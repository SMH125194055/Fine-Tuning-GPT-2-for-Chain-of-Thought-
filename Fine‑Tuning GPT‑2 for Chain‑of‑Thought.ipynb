{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e515c3d9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-11T07:26:04.835172Z",
     "iopub.status.busy": "2025-08-11T07:26:04.834972Z",
     "iopub.status.idle": "2025-08-11T07:26:06.256017Z",
     "shell.execute_reply": "2025-08-11T07:26:06.255166Z"
    },
    "papermill": {
     "duration": 1.428105,
     "end_time": "2025-08-11T07:26:06.257294",
     "exception": false,
     "start_time": "2025-08-11T07:26:04.829189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/chain-of-thought-collection/CoT_collection.json\n",
      "/kaggle/input/chain-of-thought-collection/flan_collection_subset.json\n",
      "/kaggle/input/chain-of-thought-collection/flan_collection_russian.json\n",
      "/kaggle/input/chain-of-thought-collection/flan_collection_korean.json\n",
      "/kaggle/input/chain-of-thought-collection/CoT_collection_russian.json\n",
      "/kaggle/input/chain-of-thought-collection/CoT_collection_korean.json\n",
      "/kaggle/input/chain-of-thought-collection/flan_collection_chinese.json\n",
      "/kaggle/input/chain-of-thought-collection/CoT_collection_japanese.json\n",
      "/kaggle/input/chain-of-thought-collection/flan_collection_japanese.json\n",
      "/kaggle/input/chain-of-thought-collection/CoT_collection_chinese.json\n",
      "/kaggle/input/chain-of-thought-collection/flan_collection_french.json\n",
      "/kaggle/input/chain-of-thought-collection/CoT_collection_french.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ce3d7d",
   "metadata": {
    "papermill": {
     "duration": 0.004449,
     "end_time": "2025-08-11T07:26:06.266569",
     "exception": false,
     "start_time": "2025-08-11T07:26:06.262120",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1️⃣ Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4fa8d77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T07:26:06.276216Z",
     "iopub.status.busy": "2025-08-11T07:26:06.275689Z",
     "iopub.status.idle": "2025-08-11T07:27:20.686420Z",
     "shell.execute_reply": "2025-08-11T07:27:20.685499Z"
    },
    "papermill": {
     "duration": 74.416975,
     "end_time": "2025-08-11T07:27:20.687858",
     "exception": false,
     "start_time": "2025-08-11T07:26:06.270883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\r\n",
      "bigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers datasets accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d781145",
   "metadata": {
    "papermill": {
     "duration": 0.022447,
     "end_time": "2025-08-11T07:27:20.735282",
     "exception": false,
     "start_time": "2025-08-11T07:27:20.712835",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2️⃣ Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "272017a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T07:27:20.781860Z",
     "iopub.status.busy": "2025-08-11T07:27:20.780980Z",
     "iopub.status.idle": "2025-08-11T07:27:47.600680Z",
     "shell.execute_reply": "2025-08-11T07:27:47.600001Z"
    },
    "papermill": {
     "duration": 26.844965,
     "end_time": "2025-08-11T07:27:47.602692",
     "exception": false,
     "start_time": "2025-08-11T07:27:20.757727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 07:27:35.468402: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754897255.633759      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754897255.687255      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from datasets import Dataset              # no more load_metric\n",
    "from transformers import (\n",
    "    GPT2TokenizerFast,\n",
    "    GPT2LMHeadModel,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "# reproducibility\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f448dbe",
   "metadata": {
    "papermill": {
     "duration": 0.022528,
     "end_time": "2025-08-11T07:27:47.648352",
     "exception": false,
     "start_time": "2025-08-11T07:27:47.625824",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3️⃣ Data Preprocessing\n",
    "\n",
    "Load the JSON dataset and transform each example into our input/output format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d755e905",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T07:27:47.694896Z",
     "iopub.status.busy": "2025-08-11T07:27:47.694386Z",
     "iopub.status.idle": "2025-08-11T07:28:23.682335Z",
     "shell.execute_reply": "2025-08-11T07:28:23.681399Z"
    },
    "papermill": {
     "duration": 36.034565,
     "end_time": "2025-08-11T07:28:23.705519",
     "exception": false,
     "start_time": "2025-08-11T07:27:47.670954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 10000 examples (from 1837928 raw).\n",
      "{'text': \"### Prompt: short_general_knowledge_q\\n### Context: Short general knowledge question: what all does stan kroenke own?\\n### Chain of Thought:\\nLet's think step by step.\\n<REASONING>\\n\", 'label': 'The answer is based on the fact that Stan Kroenke owns the Denver Nuggets. Therefore, the answer should be \"Denver Nuggets\". </code\\n</REASONING>\\nBased on the reasoning above, the final answer is:\\n<ANSWER> Denver Nuggets </ANSWER>'}\n"
     ]
    }
   ],
   "source": [
    "# Path to your raw JSON file on Kaggle (adjust if necessary)\n",
    "DATA_PATH = \"/kaggle/input/chain-of-thought-collection/CoT_collection.json\"  # example path\n",
    "\n",
    "# Load JSON\n",
    "with open(DATA_PATH, \"r\") as f:\n",
    "    raw = json.load(f)\n",
    "\n",
    "CAP = 10000  # jitna train/test me use karna hai, utna hi clean hoga\n",
    "\n",
    "examples = []\n",
    "seen = set()\n",
    "\n",
    "def norm(x: str) -> str:\n",
    "    return \" \".join(x.split()) if isinstance(x, str) else \"\"\n",
    "\n",
    "import re, unicodedata\n",
    "\n",
    "# --- helpers: cleaning primitives ---\n",
    "\n",
    "URL_RE = re.compile(r\"\"\"((https?://|www\\.)\\S+)|(\\S+@\\S+\\.\\S+)\"\"\", re.IGNORECASE)\n",
    "HTML_TAG_RE = re.compile(r\"<\\s*/?\\s*[a-zA-Z][^>]*>\", re.MULTILINE)\n",
    "MARKDOWN_RE = re.compile(r\"(```.*?```|`[^`]*`|\\*\\*|__|~~|>\\s*)\", re.DOTALL)\n",
    "EMOJI_RE = re.compile(\n",
    "    \"[\"                                   # basic emoji/pictograph blocks\n",
    "    \"\\U0001F300-\\U0001F6FF\"               # Misc Symbols and Pictographs\n",
    "    \"\\U0001F700-\\U0001F77F\"               # Alchemical Symbols\n",
    "    \"\\U0001F780-\\U0001F7FF\"               # Geometric Shapes Extended\n",
    "    \"\\U0001F800-\\U0001F8FF\"\n",
    "    \"\\U0001F900-\\U0001F9FF\"\n",
    "    \"\\U0001FA00-\\U0001FAFF\"\n",
    "    \"\\U00002700-\\U000027BF\"               # Dingbats\n",
    "    \"\\U00002600-\\U000026FF\"               # Misc symbols\n",
    "    \"]+\",\n",
    "    flags=re.UNICODE,\n",
    ")\n",
    "\n",
    "def normalize_quotes_dashes(s: str) -> str:\n",
    "    # curly quotes to straight; long dashes to hyphen\n",
    "    s = s.replace(\"“\", '\"').replace(\"”\", '\"').replace(\"‘\", \"'\").replace(\"’\", \"'\")\n",
    "    s = s.replace(\"—\", \"-\").replace(\"–\", \"-\")\n",
    "    return s\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    \"\"\"Light+ cleaning: keep <> for our tags, strip noise but not regular punctuation.\"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    s = unicodedata.normalize(\"NFKC\", s)\n",
    "    # remove zero-width & BOMs\n",
    "    s = s.replace(\"\\u200b\", \"\").replace(\"\\ufeff\", \"\").replace(\"\\u2060\", \"\")\n",
    "    # drop non-printable controls (keep whitespace)\n",
    "    s = \"\".join(ch for ch in s if (ch.isprintable() or ch in \"\\n\\t \"))\n",
    "    s = normalize_quotes_dashes(s)\n",
    "    # strip URLs/emails\n",
    "    s = URL_RE.sub(\" \", s)\n",
    "    # remove markdown/code fences, inline ticks, bold/underline markers, blockquote >\n",
    "    s = MARKDOWN_RE.sub(\" \", s)\n",
    "    # strip generic HTML/XML tags BUT keep our task tags <REASONING>, </REASONING>, <ANSWER>, </ANSWER>\n",
    "    s = re.sub(r\"</?code>\", \" \", s, flags=re.IGNORECASE)   # common stray code tag\n",
    "    # temporarily mask our tags so the generic stripper doesn't remove them\n",
    "    s = s.replace(\"<REASONING>\", \"§REASON_OPEN§\").replace(\"</REASONING>\", \"§REASON_CLOSE§\")\n",
    "    s = s.replace(\"<ANSWER>\", \"§ANS_OPEN§\").replace(\"</ANSWER>\", \"§ANS_CLOSE§\")\n",
    "    s = HTML_TAG_RE.sub(\" \", s)  # remove other tags\n",
    "    # unmask our tags\n",
    "    s = s.replace(\"§REASON_OPEN§\", \"<REASONING>\").replace(\"§REASON_CLOSE§\", \"</REASONING>\")\n",
    "    s = s.replace(\"§ANS_OPEN§\", \"<ANSWER>\").replace(\"§ANS_CLOSE§\", \"</ANSWER>\")\n",
    "    # remove emoji/pictographs\n",
    "    s = EMOJI_RE.sub(\" \", s)\n",
    "    # collapse noisy symbol runs (but keep <> () : / % = & - + ' \" )\n",
    "    s = re.sub(r\"[^\\w\\s.,!?;:/()<>\\-+'\\\"%=&]+\", \" \", s)\n",
    "    # tidy whitespace\n",
    "    s = re.sub(r\"[ \\t\\r\\f\\v]+\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\\n\", \"\\n\", s)\n",
    "    s = re.sub(r\"\\n\\s+\", \"\\n\", s)\n",
    "    return s.strip()\n",
    "\n",
    "def mostly_non_latin(s: str, thresh: float = 0.6) -> bool:\n",
    "    \"\"\"Heuristic: skip if text is mostly non-Latin (dataset me multilingual noise hota hai).\"\"\"\n",
    "    if not s:\n",
    "        return True\n",
    "    letters = [ch for ch in s if ch.isalpha()]\n",
    "    if not letters:\n",
    "        return False\n",
    "    latin = sum('LATIN' in unicodedata.name(ch, '') for ch in letters)\n",
    "    ratio_nonlatin = 1.0 - (latin / max(1, len(letters)))\n",
    "    return ratio_nonlatin >= thresh\n",
    "\n",
    "def strip_artifacts(s: str) -> str:\n",
    "    \"\"\"Remove common dataset artifacts leaking into rationale/target.\"\"\"\n",
    "    s = re.sub(r\"\\bAnswer\\s*:\\s*\", \" \", s, flags=re.IGNORECASE)\n",
    "    s = re.sub(r\"\\bFinal\\s*Answer\\s*:\\s*\", \" \", s, flags=re.IGNORECASE)\n",
    "    s = s.replace(\"</code>\", \" \")\n",
    "    return s.strip()\n",
    "\n",
    "# shuffle keys for random selection (clean only what we use)\n",
    "keys = list(raw.keys())\n",
    "random.shuffle(keys)\n",
    "\n",
    "MIN_COT_WC, MAX_COT_WC = 8, 512\n",
    "MAX_TGT_TOK = 50  # sanity: targets that look like long paragraphs get skipped\n",
    "\n",
    "for k in keys:\n",
    "    item = raw[k]\n",
    "\n",
    "    # essential fields present?\n",
    "    if not all([\n",
    "        item.get(\"prompt\") is not None,\n",
    "        item.get(\"source\") is not None,\n",
    "        item.get(\"rationale\") is not None,\n",
    "        item.get(\"target\") is not None,\n",
    "    ]):\n",
    "        continue\n",
    "\n",
    "    # clean + normalize\n",
    "    prompt = clean_text(norm(item.get(\"prompt\", \"\")))\n",
    "    src    = clean_text(norm(item.get(\"source\", \"\")))\n",
    "    cot    = clean_text(norm(item.get(\"rationale\", \"\")))\n",
    "    tgt    = clean_text(norm(item.get(\"target\", \"\")))\n",
    "\n",
    "    # strip common artifacts\n",
    "    cot = strip_artifacts(cot)\n",
    "    tgt = strip_artifacts(tgt)\n",
    "\n",
    "    # drop empties after cleaning\n",
    "    if not (prompt and src and cot and tgt):\n",
    "        continue\n",
    "\n",
    "    # language heuristic (skip mostly non‑Latin to keep distribution simple)\n",
    "    if mostly_non_latin(src + \" \" + cot + \" \" + tgt, thresh=0.7):\n",
    "        continue\n",
    "\n",
    "    # rationale length\n",
    "    wc = len(cot.split())\n",
    "    if wc < MIN_COT_WC or wc > MAX_COT_WC:\n",
    "        continue\n",
    "\n",
    "    # short target sanity: avoid huge essay targets\n",
    "    if len(tgt.split()) > MAX_TGT_TOK:\n",
    "        continue\n",
    "\n",
    "    # duplicate filter\n",
    "    key_tuple = (src.lower(), tgt.lower(), cot.lower())\n",
    "    if key_tuple in seen:\n",
    "        continue\n",
    "    seen.add(key_tuple)\n",
    "\n",
    "    # final formatted input/output\n",
    "    input_text = (\n",
    "        f\"### Prompt: {prompt}\\n\"\n",
    "        f\"### Context: {src}\\n\"\n",
    "        f\"### Chain of Thought:\\n\"\n",
    "        f\"Let's think step by step.\\n\"\n",
    "        f\"<REASONING>\\n\"\n",
    "    )\n",
    "    output_text = (\n",
    "        # f\"<REASONING>\\n{cot}\\n</REASONING>\\n\"\n",
    "        # f\"<ANSWER> {tgt} </ANSWER>\"\n",
    "        f\"{cot}\\n</REASONING>\\n\"\n",
    "        f\"Based on the reasoning above, the final answer is:\\n\"\n",
    "        f\"<ANSWER> {tgt} </ANSWER>\"\n",
    "    )\n",
    "\n",
    "    examples.append({\"text\": input_text, \"label\": output_text})\n",
    "\n",
    "    if len(examples) >= CAP:\n",
    "        break\n",
    "\n",
    "ds = Dataset.from_list(examples)\n",
    "print(f\"Built {len(ds)} examples (from {len(raw)} raw).\")\n",
    "print(ds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac184997",
   "metadata": {
    "papermill": {
     "duration": 0.069016,
     "end_time": "2025-08-11T07:28:23.799148",
     "exception": false,
     "start_time": "2025-08-11T07:28:23.730132",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### prompt → target pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44df2414",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T07:28:23.860028Z",
     "iopub.status.busy": "2025-08-11T07:28:23.859744Z",
     "iopub.status.idle": "2025-08-11T07:28:23.865004Z",
     "shell.execute_reply": "2025-08-11T07:28:23.864170Z"
    },
    "papermill": {
     "duration": 0.03498,
     "end_time": "2025-08-11T07:28:23.866164",
     "exception": false,
     "start_time": "2025-08-11T07:28:23.831184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Pair Preview ---\n",
      "Input:\n",
      " ### Prompt: short_general_knowledge_q\n",
      "### Context: Short general knowledge question: what all does stan kroenke own?\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "\n",
      "\n",
      "Output:\n",
      " The answer is based on the fact that Stan Kroenke owns the Denver Nuggets. Therefore, the answer should be \"Denver Nuggets\". </code\n",
      "</REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      "<ANSWER> Denver Nuggets </ANSWER>\n"
     ]
    }
   ],
   "source": [
    "# === Preview a single formatted training pair (for the assignment) ===\n",
    "sample_io = ds[0]\n",
    "print(\"\\n--- Training Pair Preview ---\")\n",
    "print(\"Input:\\n\", sample_io[\"text\"])\n",
    "print(\"\\nOutput:\\n\", sample_io[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89e9dce",
   "metadata": {
    "papermill": {
     "duration": 0.021612,
     "end_time": "2025-08-11T07:28:23.909945",
     "exception": false,
     "start_time": "2025-08-11T07:28:23.888333",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4️⃣ Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb9d444d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T07:28:23.954657Z",
     "iopub.status.busy": "2025-08-11T07:28:23.954065Z",
     "iopub.status.idle": "2025-08-11T07:28:23.973606Z",
     "shell.execute_reply": "2025-08-11T07:28:23.972790Z"
    },
    "papermill": {
     "duration": 0.043445,
     "end_time": "2025-08-11T07:28:23.975064",
     "exception": false,
     "start_time": "2025-08-11T07:28:23.931619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 8000 examples, Eval: 2000 examples\n"
     ]
    }
   ],
   "source": [
    "ds = ds.train_test_split(test_size=0.2, seed=42)\n",
    "train_ds = ds[\"train\"]\n",
    "eval_ds  = ds[\"test\"]\n",
    "print(f\"Train: {len(train_ds)} examples, Eval: {len(eval_ds)} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea9de80",
   "metadata": {
    "papermill": {
     "duration": 0.021749,
     "end_time": "2025-08-11T07:28:24.024878",
     "exception": false,
     "start_time": "2025-08-11T07:28:24.003129",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5️⃣ Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feb98711",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T07:28:24.069646Z",
     "iopub.status.busy": "2025-08-11T07:28:24.069326Z",
     "iopub.status.idle": "2025-08-11T07:28:24.074943Z",
     "shell.execute_reply": "2025-08-11T07:28:24.074249Z"
    },
    "papermill": {
     "duration": 0.029254,
     "end_time": "2025-08-11T07:28:24.076044",
     "exception": false,
     "start_time": "2025-08-11T07:28:24.046790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.6.0+cu124 | transformers: 4.52.4\n",
      "cuda available: True\n",
      "GPU: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "import torch, transformers\n",
    "print(\"torch:\", torch.__version__, \"| transformers:\", transformers.__version__)\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(0)\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e6e207d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T07:28:24.121780Z",
     "iopub.status.busy": "2025-08-11T07:28:24.121588Z",
     "iopub.status.idle": "2025-08-11T07:28:33.400891Z",
     "shell.execute_reply": "2025-08-11T07:28:33.399960Z"
    },
    "papermill": {
     "duration": 9.303902,
     "end_time": "2025-08-11T07:28:33.402269",
     "exception": false,
     "start_time": "2025-08-11T07:28:24.098367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ffe3c26b1e4980baef05c60d866486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ee7ff77d3c461b9ff2ad10601b55c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7091838727b345188c3874dd11929df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8feed41c93f4448e8ff88a44642e0221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f154271d3cc45829f8e0fcfc3ec0333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e35ad1c5b444bd2b86f794c1a74dbc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9554571b41fc4ed1bf401ff840b365a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer & model\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2-medium\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2-medium\")\n",
    "\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "try:\n",
    "    model.gradient_checkpointing_enable()\n",
    "except Exception:\n",
    "    model.config.gradient_checkpointing = True\n",
    "\n",
    "print(\"using device:\", next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5841c46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T07:28:33.448853Z",
     "iopub.status.busy": "2025-08-11T07:28:33.448639Z",
     "iopub.status.idle": "2025-08-11T07:28:42.595992Z",
     "shell.execute_reply": "2025-08-11T07:28:42.595141Z"
    },
    "papermill": {
     "duration": 9.171584,
     "end_time": "2025-08-11T07:28:42.597367",
     "exception": false,
     "start_time": "2025-08-11T07:28:33.425783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c7de00c15574955814abdebe7270039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1263 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "725b8b4944294d629952b37adcef3329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# add special tokens for reasoning/answer sections\n",
    "specials = {\"additional_special_tokens\": [\"<REASONING>\", \"</REASONING>\", \"<ANSWER>\", \"</ANSWER>\"]}\n",
    "tokenizer.add_special_tokens(specials)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "# Tokenize function\n",
    "\n",
    "def tokenize(batch):\n",
    "    # batch[\"text\"] and batch[\"label\"] are lists when batched=True\n",
    "    texts = batch[\"text\"]\n",
    "    lbls  = batch[\"label\"]\n",
    "    full  = [t + l for t, l in zip(texts, lbls)]\n",
    "\n",
    "    enc = tokenizer(\n",
    "        full,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # prompt lengths per example (for masking)\n",
    "    prompt_ids_list = tokenizer(texts, add_special_tokens=True)[\"input_ids\"]\n",
    "\n",
    "    labels = []\n",
    "    for i, ids in enumerate(enc[\"input_ids\"]):\n",
    "        lab = ids.copy()\n",
    "        cutoff = min(len(prompt_ids_list[i]), len(lab))\n",
    "        if cutoff > 0:\n",
    "            lab[:cutoff] = [-100] * cutoff\n",
    "        labels.append(lab)\n",
    "    enc[\"labels\"] = labels\n",
    "    return enc\n",
    "\n",
    "# Apply\n",
    "train_tok = train_ds.map(tokenize, remove_columns=train_ds.column_names, batched=True)\n",
    "eval_tok  = eval_ds.map(tokenize,  remove_columns=eval_ds.column_names,  batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbb388a",
   "metadata": {
    "papermill": {
     "duration": 0.033551,
     "end_time": "2025-08-11T07:28:42.661942",
     "exception": false,
     "start_time": "2025-08-11T07:28:42.628391",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6️⃣ Data Collator & Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10fdc998",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T07:28:42.745538Z",
     "iopub.status.busy": "2025-08-11T07:28:42.745262Z",
     "iopub.status.idle": "2025-08-11T07:28:42.779927Z",
     "shell.execute_reply": "2025-08-11T07:28:42.779141Z"
    },
    "papermill": {
     "duration": 0.086453,
     "end_time": "2025-08-11T07:28:42.781155",
     "exception": false,
     "start_time": "2025-08-11T07:28:42.694702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 6️⃣ Data Collator & Training Arguments (updated for logging)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "\n",
    "# keep a small dict of key training settings for the write-up\n",
    "train_settings = {\n",
    "    \"model\": \"gpt2-medium\",\n",
    "    \"train_examples\": len(train_ds),\n",
    "    \"eval_examples\": len(eval_ds),\n",
    "    \"per_device_train_batch_size\": 2,\n",
    "    \"per_device_eval_batch_size\": 4,\n",
    "    \"num_train_epochs\": 8,\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"weight_decay\": 0.1,\n",
    "    \"fp16\": True,\n",
    "}\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"gpt2_cot_finetuned\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "\n",
    "    # logging\n",
    "    logging_dir=\"runs\",            # where to write TensorBoard logs\n",
    "    logging_steps=20,              # print/log every 20 training steps\n",
    "    report_to=\"tensorboard\",       # send logs to TensorBoard\n",
    "\n",
    "    # progress bar\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.1,\n",
    "    save_total_limit=2,\n",
    "    fp16=True,                     # mixed precision\n",
    "\n",
    "    # ensure the tqdm bar is visible\n",
    "    disable_tqdm=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb1f72f",
   "metadata": {
    "papermill": {
     "duration": 0.034185,
     "end_time": "2025-08-11T07:28:42.849600",
     "exception": false,
     "start_time": "2025-08-11T07:28:42.815415",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7️⃣ Trainer Initialization & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6149271",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T07:28:42.911887Z",
     "iopub.status.busy": "2025-08-11T07:28:42.911618Z",
     "iopub.status.idle": "2025-08-11T09:54:43.234787Z",
     "shell.execute_reply": "2025-08-11T09:54:43.233919Z"
    },
    "papermill": {
     "duration": 8760.358556,
     "end_time": "2025-08-11T09:54:43.236246",
     "exception": false,
     "start_time": "2025-08-11T07:28:42.877690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Epoch 1/3 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12000' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12000/12000 2:18:26, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.251400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.833900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.728700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.578300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.513600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.350300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.378200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.520800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.333800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.277700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.329300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2.333400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2.406300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.292100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.250900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>2.189100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.233100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>2.193200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.208700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>2.340900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>2.206600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>2.103800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>2.094400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.354500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>2.283900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>2.286300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>1.924700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>2.149900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.106700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>2.150300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>2.085700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>2.181200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.148400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.053600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>2.102000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>2.094600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>1.854200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>1.991000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.945800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.324600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.289900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>2.197100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2.037200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.041300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>2.062400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>1.989300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>1.934800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.068000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.138800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>2.067500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>2.016100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>2.151200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>2.068900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.005200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>2.069200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>1.983800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>2.145900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>1.923900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.951300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>2.032400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>1.951000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>1.931900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>1.926500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.988500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>1.885300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>2.010700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>2.020900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>1.945700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.991900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>2.029300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>1.921400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>2.033200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>1.972700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.312200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520</td>\n",
       "      <td>2.102200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540</td>\n",
       "      <td>2.028300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>2.048500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1580</td>\n",
       "      <td>2.081500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.971700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>1.730400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1640</td>\n",
       "      <td>2.134300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1660</td>\n",
       "      <td>2.041200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>2.012300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>2.032700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1720</td>\n",
       "      <td>1.986500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>1.904000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1760</td>\n",
       "      <td>1.774700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1780</td>\n",
       "      <td>2.138300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.056300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1820</td>\n",
       "      <td>2.021600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1840</td>\n",
       "      <td>1.776100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>1.907400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1880</td>\n",
       "      <td>1.893600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>1.923300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>2.008100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1940</td>\n",
       "      <td>1.749600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1960</td>\n",
       "      <td>1.922800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>1.954600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.970600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020</td>\n",
       "      <td>1.785900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2040</td>\n",
       "      <td>1.969200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2060</td>\n",
       "      <td>2.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2080</td>\n",
       "      <td>1.961200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>1.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2120</td>\n",
       "      <td>2.014200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2140</td>\n",
       "      <td>1.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2160</td>\n",
       "      <td>1.886400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2180</td>\n",
       "      <td>2.184800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>2.154900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2220</td>\n",
       "      <td>1.835100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2240</td>\n",
       "      <td>1.876400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2260</td>\n",
       "      <td>1.901500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2280</td>\n",
       "      <td>1.884900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>1.981600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2320</td>\n",
       "      <td>1.825400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2340</td>\n",
       "      <td>1.879400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2360</td>\n",
       "      <td>1.716400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2380</td>\n",
       "      <td>1.828900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.905700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2420</td>\n",
       "      <td>1.828000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2440</td>\n",
       "      <td>2.095100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2460</td>\n",
       "      <td>1.970900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2480</td>\n",
       "      <td>1.976600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.038900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2520</td>\n",
       "      <td>2.056600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2540</td>\n",
       "      <td>2.040300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2560</td>\n",
       "      <td>1.988000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2580</td>\n",
       "      <td>2.048400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>1.836400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2620</td>\n",
       "      <td>1.838800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2640</td>\n",
       "      <td>1.945600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2660</td>\n",
       "      <td>2.008800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2680</td>\n",
       "      <td>1.794100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>1.798400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2720</td>\n",
       "      <td>2.007900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2740</td>\n",
       "      <td>1.828700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2760</td>\n",
       "      <td>1.831400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2780</td>\n",
       "      <td>1.740100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>1.999000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2820</td>\n",
       "      <td>1.959000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2840</td>\n",
       "      <td>1.944900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2860</td>\n",
       "      <td>1.796200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2880</td>\n",
       "      <td>1.943200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>1.869100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2920</td>\n",
       "      <td>1.981300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2940</td>\n",
       "      <td>1.871000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2960</td>\n",
       "      <td>1.810400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2980</td>\n",
       "      <td>1.804900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.689000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3020</td>\n",
       "      <td>1.894700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3040</td>\n",
       "      <td>1.900100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3060</td>\n",
       "      <td>1.975300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3080</td>\n",
       "      <td>2.013600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>1.854200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3120</td>\n",
       "      <td>1.831700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3140</td>\n",
       "      <td>1.750700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3160</td>\n",
       "      <td>1.889400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3180</td>\n",
       "      <td>1.980800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>1.823300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3220</td>\n",
       "      <td>1.742100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3240</td>\n",
       "      <td>1.905600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3260</td>\n",
       "      <td>1.976900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3280</td>\n",
       "      <td>1.659300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>1.891400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3320</td>\n",
       "      <td>1.877500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3340</td>\n",
       "      <td>1.698700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3360</td>\n",
       "      <td>1.753200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3380</td>\n",
       "      <td>1.803700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>1.749700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3420</td>\n",
       "      <td>1.752300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3440</td>\n",
       "      <td>2.073500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3460</td>\n",
       "      <td>1.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3480</td>\n",
       "      <td>1.749600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.925400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3520</td>\n",
       "      <td>1.820500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3540</td>\n",
       "      <td>2.087300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3560</td>\n",
       "      <td>1.838800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3580</td>\n",
       "      <td>1.803700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>1.846700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3620</td>\n",
       "      <td>1.894200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3640</td>\n",
       "      <td>2.148400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3660</td>\n",
       "      <td>1.697500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3680</td>\n",
       "      <td>1.647400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>1.651200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3720</td>\n",
       "      <td>1.839500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3740</td>\n",
       "      <td>1.819200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3760</td>\n",
       "      <td>1.975400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3780</td>\n",
       "      <td>1.755900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>1.872300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3820</td>\n",
       "      <td>1.775500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3840</td>\n",
       "      <td>1.841100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3860</td>\n",
       "      <td>1.755800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3880</td>\n",
       "      <td>1.861300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>1.765500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3920</td>\n",
       "      <td>1.867700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3940</td>\n",
       "      <td>1.875800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3960</td>\n",
       "      <td>1.698800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3980</td>\n",
       "      <td>1.785900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4020</td>\n",
       "      <td>1.691300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4040</td>\n",
       "      <td>1.756600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4060</td>\n",
       "      <td>1.647500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4080</td>\n",
       "      <td>1.514100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>1.748800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4120</td>\n",
       "      <td>1.408400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4140</td>\n",
       "      <td>1.762700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4160</td>\n",
       "      <td>1.728600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4180</td>\n",
       "      <td>1.563200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>1.909600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4220</td>\n",
       "      <td>1.422300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4240</td>\n",
       "      <td>1.606200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4260</td>\n",
       "      <td>1.621600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4280</td>\n",
       "      <td>1.614700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>1.772200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4320</td>\n",
       "      <td>1.595900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4340</td>\n",
       "      <td>1.660900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4360</td>\n",
       "      <td>1.798300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4380</td>\n",
       "      <td>1.515100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>1.654600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4420</td>\n",
       "      <td>1.643700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4440</td>\n",
       "      <td>1.515900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4460</td>\n",
       "      <td>1.606400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4480</td>\n",
       "      <td>1.891000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.760400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4520</td>\n",
       "      <td>1.619400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4540</td>\n",
       "      <td>1.781100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4560</td>\n",
       "      <td>1.735300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4580</td>\n",
       "      <td>1.646400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>1.625700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4620</td>\n",
       "      <td>1.652500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4640</td>\n",
       "      <td>1.663500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4660</td>\n",
       "      <td>1.748900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4680</td>\n",
       "      <td>1.675800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>1.581100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4720</td>\n",
       "      <td>1.684600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4740</td>\n",
       "      <td>1.656000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4760</td>\n",
       "      <td>1.660400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4780</td>\n",
       "      <td>1.751900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>1.661600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4820</td>\n",
       "      <td>1.533200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4840</td>\n",
       "      <td>1.715700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4860</td>\n",
       "      <td>1.609200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4880</td>\n",
       "      <td>1.539300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>1.604900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4920</td>\n",
       "      <td>1.612400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4940</td>\n",
       "      <td>1.851200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4960</td>\n",
       "      <td>1.685500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4980</td>\n",
       "      <td>1.770900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.488400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5020</td>\n",
       "      <td>1.706300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5040</td>\n",
       "      <td>1.535000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5060</td>\n",
       "      <td>1.420700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5080</td>\n",
       "      <td>1.815000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>1.671000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5120</td>\n",
       "      <td>1.678400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5140</td>\n",
       "      <td>1.736600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5160</td>\n",
       "      <td>1.648700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5180</td>\n",
       "      <td>1.587200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>1.639800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5220</td>\n",
       "      <td>1.478400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5240</td>\n",
       "      <td>1.767200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5260</td>\n",
       "      <td>1.562700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5280</td>\n",
       "      <td>1.672300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>1.817900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5320</td>\n",
       "      <td>1.822200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5340</td>\n",
       "      <td>1.630200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5360</td>\n",
       "      <td>1.469100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5380</td>\n",
       "      <td>1.735000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>1.596400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5420</td>\n",
       "      <td>1.539400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5440</td>\n",
       "      <td>1.755600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5460</td>\n",
       "      <td>1.782400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5480</td>\n",
       "      <td>1.439600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.606500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5520</td>\n",
       "      <td>1.531400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5540</td>\n",
       "      <td>1.710700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5560</td>\n",
       "      <td>1.731100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5580</td>\n",
       "      <td>1.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>1.595700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5620</td>\n",
       "      <td>1.527100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5640</td>\n",
       "      <td>1.546200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5660</td>\n",
       "      <td>1.569300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5680</td>\n",
       "      <td>1.597900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>1.635100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5720</td>\n",
       "      <td>1.461900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5740</td>\n",
       "      <td>1.727300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5760</td>\n",
       "      <td>1.507800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5780</td>\n",
       "      <td>1.570400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>1.620800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5820</td>\n",
       "      <td>1.727100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5840</td>\n",
       "      <td>1.582400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5860</td>\n",
       "      <td>1.633300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5880</td>\n",
       "      <td>1.729300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>1.493100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5920</td>\n",
       "      <td>1.743100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5940</td>\n",
       "      <td>1.576400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5960</td>\n",
       "      <td>1.623000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5980</td>\n",
       "      <td>1.584900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.714300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6020</td>\n",
       "      <td>1.729300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6040</td>\n",
       "      <td>1.524900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6060</td>\n",
       "      <td>1.662200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6080</td>\n",
       "      <td>1.663700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>1.812200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6120</td>\n",
       "      <td>1.292100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6140</td>\n",
       "      <td>1.534600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6160</td>\n",
       "      <td>1.518200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6180</td>\n",
       "      <td>1.512100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>1.538100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6220</td>\n",
       "      <td>1.565900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6240</td>\n",
       "      <td>1.764300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6260</td>\n",
       "      <td>1.608300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6280</td>\n",
       "      <td>1.785300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>1.534400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6320</td>\n",
       "      <td>1.682200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6340</td>\n",
       "      <td>1.555300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6360</td>\n",
       "      <td>1.818700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6380</td>\n",
       "      <td>1.510400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>1.660400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6420</td>\n",
       "      <td>1.477000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6440</td>\n",
       "      <td>1.803100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6460</td>\n",
       "      <td>1.499000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6480</td>\n",
       "      <td>1.416300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.406800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6520</td>\n",
       "      <td>1.488900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6540</td>\n",
       "      <td>1.598300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6560</td>\n",
       "      <td>1.771400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6580</td>\n",
       "      <td>1.662300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>1.649600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6620</td>\n",
       "      <td>1.520500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6640</td>\n",
       "      <td>1.542900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6660</td>\n",
       "      <td>1.644100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6680</td>\n",
       "      <td>1.539700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>1.700500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6720</td>\n",
       "      <td>1.514100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6740</td>\n",
       "      <td>1.547800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6760</td>\n",
       "      <td>1.603900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6780</td>\n",
       "      <td>1.486500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>1.519200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6820</td>\n",
       "      <td>1.611000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6840</td>\n",
       "      <td>1.620900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6860</td>\n",
       "      <td>1.435300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6880</td>\n",
       "      <td>1.702200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>1.612900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6920</td>\n",
       "      <td>1.546900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6940</td>\n",
       "      <td>1.703900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6960</td>\n",
       "      <td>1.717400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6980</td>\n",
       "      <td>1.587500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.626200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7020</td>\n",
       "      <td>1.611000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7040</td>\n",
       "      <td>1.620500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7060</td>\n",
       "      <td>1.899500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7080</td>\n",
       "      <td>1.767300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>1.750600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7120</td>\n",
       "      <td>1.767600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7140</td>\n",
       "      <td>1.627500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7160</td>\n",
       "      <td>1.681000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7180</td>\n",
       "      <td>1.624000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>1.515300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7220</td>\n",
       "      <td>1.580200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7240</td>\n",
       "      <td>1.485900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7260</td>\n",
       "      <td>1.507100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7280</td>\n",
       "      <td>1.632800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>1.546000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7320</td>\n",
       "      <td>1.617000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7340</td>\n",
       "      <td>1.692400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7360</td>\n",
       "      <td>1.484900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7380</td>\n",
       "      <td>1.617000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>1.498700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7420</td>\n",
       "      <td>1.698100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7440</td>\n",
       "      <td>1.646700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7460</td>\n",
       "      <td>1.530200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7480</td>\n",
       "      <td>1.454700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>1.714800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7520</td>\n",
       "      <td>1.660500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7540</td>\n",
       "      <td>1.724900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7560</td>\n",
       "      <td>1.458800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7580</td>\n",
       "      <td>1.699100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>1.583800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7620</td>\n",
       "      <td>1.617700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7640</td>\n",
       "      <td>1.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7660</td>\n",
       "      <td>1.578000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7680</td>\n",
       "      <td>1.690900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>1.648500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7720</td>\n",
       "      <td>1.694900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7740</td>\n",
       "      <td>1.600200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7760</td>\n",
       "      <td>1.673700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7780</td>\n",
       "      <td>1.604100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>1.490500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7820</td>\n",
       "      <td>1.451300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7840</td>\n",
       "      <td>1.652600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7860</td>\n",
       "      <td>1.662300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7880</td>\n",
       "      <td>1.718000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>1.645900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7920</td>\n",
       "      <td>1.601000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7940</td>\n",
       "      <td>1.734500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7960</td>\n",
       "      <td>1.600800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7980</td>\n",
       "      <td>1.606700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.559400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8020</td>\n",
       "      <td>1.575700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8040</td>\n",
       "      <td>1.441100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8060</td>\n",
       "      <td>1.745200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8080</td>\n",
       "      <td>1.554700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>1.587700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8120</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8140</td>\n",
       "      <td>1.516000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8160</td>\n",
       "      <td>1.303000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8180</td>\n",
       "      <td>1.696000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>1.663900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8220</td>\n",
       "      <td>1.514100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8240</td>\n",
       "      <td>1.561600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8260</td>\n",
       "      <td>1.542400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8280</td>\n",
       "      <td>1.447900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>1.429000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8320</td>\n",
       "      <td>1.589500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8340</td>\n",
       "      <td>1.512600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8360</td>\n",
       "      <td>1.545500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8380</td>\n",
       "      <td>1.586400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>1.672000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8420</td>\n",
       "      <td>1.670300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8440</td>\n",
       "      <td>1.546800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8460</td>\n",
       "      <td>1.477600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8480</td>\n",
       "      <td>1.438100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>1.489400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8520</td>\n",
       "      <td>1.356300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8540</td>\n",
       "      <td>1.664500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8560</td>\n",
       "      <td>1.670500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8580</td>\n",
       "      <td>1.558300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>1.503300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8620</td>\n",
       "      <td>1.567100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8640</td>\n",
       "      <td>1.540900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8660</td>\n",
       "      <td>1.481100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8680</td>\n",
       "      <td>1.188500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>1.552300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8720</td>\n",
       "      <td>1.406700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8740</td>\n",
       "      <td>1.568300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8760</td>\n",
       "      <td>1.486500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8780</td>\n",
       "      <td>1.671300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>1.622800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8820</td>\n",
       "      <td>1.578000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8840</td>\n",
       "      <td>1.496700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8860</td>\n",
       "      <td>1.320800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8880</td>\n",
       "      <td>1.813900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>1.503900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8920</td>\n",
       "      <td>1.633100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8940</td>\n",
       "      <td>1.561700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8960</td>\n",
       "      <td>1.558900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8980</td>\n",
       "      <td>1.351800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.666300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9020</td>\n",
       "      <td>1.366500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9040</td>\n",
       "      <td>1.489000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9060</td>\n",
       "      <td>1.698400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9080</td>\n",
       "      <td>1.555200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>1.413700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9120</td>\n",
       "      <td>1.631400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9140</td>\n",
       "      <td>1.558000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9160</td>\n",
       "      <td>1.557400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9180</td>\n",
       "      <td>1.232700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>1.453300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9220</td>\n",
       "      <td>1.581400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9240</td>\n",
       "      <td>1.660900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9260</td>\n",
       "      <td>1.387700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9280</td>\n",
       "      <td>1.626900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>1.389100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9320</td>\n",
       "      <td>1.617800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9340</td>\n",
       "      <td>1.437900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9360</td>\n",
       "      <td>1.655800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9380</td>\n",
       "      <td>1.569500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>1.363800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9420</td>\n",
       "      <td>1.435100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9440</td>\n",
       "      <td>1.617300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9460</td>\n",
       "      <td>1.455900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9480</td>\n",
       "      <td>1.346100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>1.609300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9520</td>\n",
       "      <td>1.471400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9540</td>\n",
       "      <td>1.624000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9560</td>\n",
       "      <td>1.740800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9580</td>\n",
       "      <td>1.347400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>1.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9620</td>\n",
       "      <td>1.537000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9640</td>\n",
       "      <td>1.717700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9660</td>\n",
       "      <td>1.522000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9680</td>\n",
       "      <td>1.558800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9700</td>\n",
       "      <td>1.450400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9720</td>\n",
       "      <td>1.490800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9740</td>\n",
       "      <td>1.511400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9760</td>\n",
       "      <td>1.568800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9780</td>\n",
       "      <td>1.489300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>1.572500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9820</td>\n",
       "      <td>1.423300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9840</td>\n",
       "      <td>1.366700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9860</td>\n",
       "      <td>1.608200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9880</td>\n",
       "      <td>1.572400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9900</td>\n",
       "      <td>1.479100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9920</td>\n",
       "      <td>1.560600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9940</td>\n",
       "      <td>1.557600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9960</td>\n",
       "      <td>1.664600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9980</td>\n",
       "      <td>1.425400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.436100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10020</td>\n",
       "      <td>1.438500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10040</td>\n",
       "      <td>1.470800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10060</td>\n",
       "      <td>1.611700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10080</td>\n",
       "      <td>1.566400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10100</td>\n",
       "      <td>1.473100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10120</td>\n",
       "      <td>1.367100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10140</td>\n",
       "      <td>1.723000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10160</td>\n",
       "      <td>1.526700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10180</td>\n",
       "      <td>1.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>1.361900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10220</td>\n",
       "      <td>1.318200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10240</td>\n",
       "      <td>1.422700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10260</td>\n",
       "      <td>1.626100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10280</td>\n",
       "      <td>1.335600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10300</td>\n",
       "      <td>1.560400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10320</td>\n",
       "      <td>1.391800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10340</td>\n",
       "      <td>1.523400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10360</td>\n",
       "      <td>1.467500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10380</td>\n",
       "      <td>1.465900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>1.466900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10420</td>\n",
       "      <td>1.617500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10440</td>\n",
       "      <td>1.897700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10460</td>\n",
       "      <td>1.372900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10480</td>\n",
       "      <td>1.456200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>1.486200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10520</td>\n",
       "      <td>1.294200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10540</td>\n",
       "      <td>1.616600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10560</td>\n",
       "      <td>1.552800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10580</td>\n",
       "      <td>1.372300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>1.545700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10620</td>\n",
       "      <td>1.434300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10640</td>\n",
       "      <td>1.362800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10660</td>\n",
       "      <td>1.404500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10680</td>\n",
       "      <td>1.631300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10700</td>\n",
       "      <td>1.414100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10720</td>\n",
       "      <td>1.503100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10740</td>\n",
       "      <td>1.356400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10760</td>\n",
       "      <td>1.429900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10780</td>\n",
       "      <td>1.365200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>1.484300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10820</td>\n",
       "      <td>1.537300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10840</td>\n",
       "      <td>1.472200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10860</td>\n",
       "      <td>1.499100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10880</td>\n",
       "      <td>1.546200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10900</td>\n",
       "      <td>1.487400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10920</td>\n",
       "      <td>1.427000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10940</td>\n",
       "      <td>1.391300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10960</td>\n",
       "      <td>1.457700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10980</td>\n",
       "      <td>1.457800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>1.606200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11020</td>\n",
       "      <td>1.391800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11040</td>\n",
       "      <td>1.647500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11060</td>\n",
       "      <td>1.418400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11080</td>\n",
       "      <td>1.612900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11100</td>\n",
       "      <td>1.398400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11120</td>\n",
       "      <td>1.618800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11140</td>\n",
       "      <td>1.640900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11160</td>\n",
       "      <td>1.497500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11180</td>\n",
       "      <td>1.379100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>1.616200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11220</td>\n",
       "      <td>1.503600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11240</td>\n",
       "      <td>1.437100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11260</td>\n",
       "      <td>1.422900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11280</td>\n",
       "      <td>1.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11300</td>\n",
       "      <td>1.605200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11320</td>\n",
       "      <td>1.724000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11340</td>\n",
       "      <td>1.495300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11360</td>\n",
       "      <td>1.446100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11380</td>\n",
       "      <td>1.520700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11400</td>\n",
       "      <td>1.613800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11420</td>\n",
       "      <td>1.248600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11440</td>\n",
       "      <td>1.641800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11460</td>\n",
       "      <td>1.553500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11480</td>\n",
       "      <td>1.524200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>1.381700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11520</td>\n",
       "      <td>1.406100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11540</td>\n",
       "      <td>1.574200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11560</td>\n",
       "      <td>1.365800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11580</td>\n",
       "      <td>1.386600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11600</td>\n",
       "      <td>1.751400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11620</td>\n",
       "      <td>1.490600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11640</td>\n",
       "      <td>1.447200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11660</td>\n",
       "      <td>1.441700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11680</td>\n",
       "      <td>1.422000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11700</td>\n",
       "      <td>1.352500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11720</td>\n",
       "      <td>1.491000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11740</td>\n",
       "      <td>1.530700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11760</td>\n",
       "      <td>1.730900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11780</td>\n",
       "      <td>1.488500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11800</td>\n",
       "      <td>1.678400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11820</td>\n",
       "      <td>1.516900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11840</td>\n",
       "      <td>1.418000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11860</td>\n",
       "      <td>1.584300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11880</td>\n",
       "      <td>1.313100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11900</td>\n",
       "      <td>1.324600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11920</td>\n",
       "      <td>1.368400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11940</td>\n",
       "      <td>1.563100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11960</td>\n",
       "      <td>1.422400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11980</td>\n",
       "      <td>1.590500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>1.429600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 07:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 → eval_loss = 1.7020\n",
      "  ✅ New best — saving checkpoint.\n",
      "\n",
      "===== Epoch 2/3 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12000' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12000/12000 : < :, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 → eval_loss = 1.7020\n",
      "  No improvement for 1 epoch(s).\n",
      "\n",
      "===== Epoch 3/3 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12000' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12000/12000 : < :, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 → eval_loss = 1.7020\n",
      "  No improvement for 2 epoch(s).\n",
      "⏹ Early stop (patience=2).\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=eval_tok,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "# trainer.train()\n",
    "# Manual early‐stopping loop\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "patience = 2\n",
    "wait = 0\n",
    "max_epochs = int(training_args.num_train_epochs)\n",
    "\n",
    "for epoch in range(1, max_epochs + 1):\n",
    "    print(f\"\\n===== Epoch {epoch}/{max_epochs} =====\")\n",
    "    trainer.train(resume_from_checkpoint=(epoch > 1))\n",
    "    metrics = trainer.evaluate()\n",
    "    val_loss = metrics.get(\"eval_loss\")\n",
    "    print(f\"Epoch {epoch} → eval_loss = {val_loss:.4f}\" if val_loss is not None else \"No eval_loss\")\n",
    "\n",
    "    if val_loss is not None and val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        wait = 0\n",
    "        print(\"  ✅ New best — saving checkpoint.\")\n",
    "        trainer.save_model(\"best-model\")\n",
    "    else:\n",
    "        wait += 1\n",
    "        print(f\"  No improvement for {wait} epoch(s).\")\n",
    "        if wait >= patience:\n",
    "            print(f\"⏹ Early stop (patience={patience}).\")\n",
    "            break\n",
    "            \n",
    "# Save final model & tokenizer\n",
    "trainer.save_model(\"gpt2_cot_final\")\n",
    "tokenizer.save_pretrained(\"gpt2_cot_final\")\n",
    "\n",
    "# -- Save a tiny Model Card / README for submission --\n",
    "with open(\"gpt2_cot_final/README.md\", \"w\") as f:\n",
    "    f.write(\"# GPT-2 CoT Fine-tune\\n\")\n",
    "    f.write(\"- Base model: gpt2\\n\")\n",
    "    f.write(f\"- Train examples: {len(train_ds)}\\n\")\n",
    "    f.write(f\"- Eval examples: {len(eval_ds)}\\n\")\n",
    "    f.write(f\"- LR: {train_settings['learning_rate']}, Epochs: {train_settings['num_train_epochs']}, BS: {train_settings['per_device_train_batch_size']}\\n\")\n",
    "    f.write(\"- Data: Chain-of-Thought Collection (Kaggle). For research/educational use.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39b7f092",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T09:54:43.287991Z",
     "iopub.status.busy": "2025-08-11T09:54:43.287751Z",
     "iopub.status.idle": "2025-08-11T09:54:54.854770Z",
     "shell.execute_reply": "2025-08-11T09:54:54.854027Z"
    },
    "papermill": {
     "duration": 11.593701,
     "end_time": "2025-08-11T09:54:54.856000",
     "exception": false,
     "start_time": "2025-08-11T09:54:43.262299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        (async () => {\n",
       "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
       "            url.searchParams.set('tensorboardColab', 'true');\n",
       "            const iframe = document.createElement('iframe');\n",
       "            iframe.src = url;\n",
       "            iframe.setAttribute('width', '100%');\n",
       "            iframe.setAttribute('height', '800');\n",
       "            iframe.setAttribute('frameborder', 0);\n",
       "            document.body.appendChild(iframe);\n",
       "        })();\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# install tensorboard if needed\n",
    "!pip install -q tensorboard\n",
    "\n",
    "# load the tensorboard extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# launch it pointing at our logs folder\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8ca8f0",
   "metadata": {
    "papermill": {
     "duration": 0.024977,
     "end_time": "2025-08-11T09:54:54.906918",
     "exception": false,
     "start_time": "2025-08-11T09:54:54.881941",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 8️⃣ Inference & Qualitative Evaluation\n",
    "\n",
    "Generate CoT outputs on some unseen examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92e93629",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T09:54:54.958724Z",
     "iopub.status.busy": "2025-08-11T09:54:54.958452Z",
     "iopub.status.idle": "2025-08-11T09:54:54.962913Z",
     "shell.execute_reply": "2025-08-11T09:54:54.962384Z"
    },
    "papermill": {
     "duration": 0.031826,
     "end_time": "2025-08-11T09:54:54.963946",
     "exception": false,
     "start_time": "2025-08-11T09:54:54.932120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def safe_sample(dataset, k=10, seed=None):\n",
    "    \"\"\"\n",
    "    Returns up to k random samples from dataset.\n",
    "    Will return fewer if dataset is smaller.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    dataset_size = len(dataset)\n",
    "    if dataset_size <= k:\n",
    "        return list(dataset)\n",
    "    return random.sample(list(dataset), k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6f5a048",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T09:54:55.014596Z",
     "iopub.status.busy": "2025-08-11T09:54:55.014125Z",
     "iopub.status.idle": "2025-08-11T09:54:55.018368Z",
     "shell.execute_reply": "2025-08-11T09:54:55.017795Z"
    },
    "papermill": {
     "duration": 0.030712,
     "end_time": "2025-08-11T09:54:55.019382",
     "exception": false,
     "start_time": "2025-08-11T09:54:54.988670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_prompt_source(text):\n",
    "    \"\"\"\n",
    "    Extracts (prompt, source) from the combined text field.\n",
    "    Adjust splitting logic to match your dataset format.\n",
    "    \"\"\"\n",
    "    # Example if your text is in format: \"### Prompt: ...\\n### Context: ...\"\n",
    "    prompt, source = \"\", text\n",
    "    if \"### Prompt:\" in text and \"### Context:\" in text:\n",
    "        parts = text.split(\"### Prompt:\", 1)[1].split(\"### Context:\", 1)\n",
    "        prompt = parts[0].strip()\n",
    "        source = parts[1].strip()\n",
    "    return prompt, source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ac094f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T09:54:55.071904Z",
     "iopub.status.busy": "2025-08-11T09:54:55.071401Z",
     "iopub.status.idle": "2025-08-11T09:54:55.078483Z",
     "shell.execute_reply": "2025-08-11T09:54:55.077744Z"
    },
    "papermill": {
     "duration": 0.035344,
     "end_time": "2025-08-11T09:54:55.079658",
     "exception": false,
     "start_time": "2025-08-11T09:54:55.044314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def normalize_text(s):\n",
    "    \"\"\"Lowercase, remove punctuation, articles, and extra whitespace.\"\"\"\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        return ''.join(ch for ch in text if ch not in string.punctuation)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def exact_match(prediction, ground_truth):\n",
    "    \"\"\"True if normalized prediction exactly matches normalized ground truth.\"\"\"\n",
    "    return normalize_text(prediction) == normalize_text(ground_truth)\n",
    "\n",
    "def f1_token(prediction, ground_truth):\n",
    "    \"\"\"F1 score between prediction and ground truth based on token overlap.\"\"\"\n",
    "    pred_tokens = normalize_text(prediction).split()\n",
    "    gt_tokens = normalize_text(ground_truth).split()\n",
    "    common = set(pred_tokens) & set(gt_tokens)\n",
    "    num_same = sum(min(pred_tokens.count(tok), gt_tokens.count(tok)) for tok in common)\n",
    "\n",
    "    if len(pred_tokens) == 0 or len(gt_tokens) == 0:\n",
    "        return int(pred_tokens == gt_tokens)\n",
    "    if num_same == 0:\n",
    "        return 0\n",
    "\n",
    "    precision = num_same / len(pred_tokens)\n",
    "    recall = num_same / len(gt_tokens)\n",
    "    return (2 * precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5deded1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T09:54:55.131121Z",
     "iopub.status.busy": "2025-08-11T09:54:55.130937Z",
     "iopub.status.idle": "2025-08-11T09:55:56.075133Z",
     "shell.execute_reply": "2025-08-11T09:55:56.074349Z"
    },
    "papermill": {
     "duration": 61.000069,
     "end_time": "2025-08-11T09:55:56.104917",
     "exception": false,
     "start_time": "2025-08-11T09:54:55.104848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] evaluating on 25 examples (eval_ds size = 2000)\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "SOURCE: See the multi-choice question below: Sentence 1: horrible i guess i would try and have somebody at the house as long as they were healthy enough but sometimes they're Sentence 2: It is unhealthy, I would never try those because I care about myself. If the first sentence is true, then is the second sentence true? OPTIONS: - yes - it is not possible to tell - no\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "\n",
      "MODEL RAW OUTPUT:\n",
      " ### Prompt: 4\n",
      "### Context: See the multi-choice question below: Sentence 1: horrible i guess i would try and have somebody at the house as long as they were healthy enough but sometimes they're Sentence 2: It is unhealthy, I would never try those because I care about myself. If the first sentence is true, then is the second sentence true? OPTIONS: - yes - it is not possible to tell - no\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "The first sentence states that the person would not try to have someone at the home if they were unhealthy, which contradicts the second statement. Therefore, the answer is \"no\".\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " no  no  no\n",
      " yes  yes  yes\n",
      "</REASONING>\n",
      "<ANSWER> yes n  yes </code\n",
      "  yes no  yes <code\n",
      "Based\n",
      "Based upon the reasoning described above, our final answer would be:\n",
      " no  Yes  Yes </code </ANSWER> </ANSWER>\n",
      "\n",
      "PARSED RATIONALE:\n",
      " The first sentence states that the person would not try to have someone at the home if they were unhealthy, which contradicts the second statement. Therefore, the answer is \"no\".\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " no  no  no\n",
      " yes  yes  yes\n",
      "</REASONING>\n",
      "PARSED ANSWER:\n",
      " yes n  yes </code\n",
      "  yes no  yes <code\n",
      "Based\n",
      "Based upon the reasoning described above, our final answer would be:\n",
      " no  Yes  Yes </code </ANSWER>\n",
      "\n",
      "GROUND TRUTH RATIONALE + ANSWER:\n",
      " The first sentence describes a situation in which the author would try and have somebody at their house, as long as they were healthy enough. The second sentence states that it is unhealthy to do so and therefore, one should never attempt such a thing because of how much they care about themselves. This directly contradicts what was mentioned previously. Therefore the answer is \"no\"\n",
      "</REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      "<ANSWER> no </ANSWER>\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "SOURCE: how many championships do the crimson tide have??\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "\n",
      "MODEL RAW OUTPUT:\n",
      " ### Prompt: 1\n",
      "### Context: how many championships do the crimson tide have??\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "The answer is \"three\".\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " three  three  three\n",
      " n  n  n\n",
      " \n",
      "Based   3  4  5  6  7  8\n",
      "</REASONING>\n",
      "<ANSWER> 4 , 5 , 6 , 7 , 8  4, 5 ,  6 ,  7 ,  8   \n",
      "  4 5 6 7 8  8 8  9  10  11  12  13  14  15  16  17  18   19  20  21 </ANSWER> </ANSWER>\n",
      "\n",
      "PARSED RATIONALE:\n",
      " The answer is \"three\".\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " three  three  three\n",
      " n  n  n\n",
      " \n",
      "Based   3  4  5  6  7  8\n",
      "</REASONING>\n",
      "PARSED ANSWER:\n",
      " 4 , 5 , 6 , 7 , 8  4, 5 ,  6 ,  7 ,  8   \n",
      "  4 5 6 7 8  8 8  9  10  11  12  13  14  15  16  17  18   19  20  21 </ANSWER>\n",
      "\n",
      "GROUND TRUTH RATIONALE + ANSWER:\n",
      " The answer is based on the number of championships that are won by Alabama Crimson Tide. Alabama has won 17 national titles, including 13 Associated Press (AP) Poll and 10 Coaches' Poll crowns since 1925.\n",
      "</REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      "<ANSWER> 17 </ANSWER>\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "SOURCE: Read the following context and answer the question. Context: She kicked him in the stomach . \" Leave me alone and let me sleep . \" Roughly , he grabbed her arm and yanked her over . \" Get up now or starve , \" he demanded , and she wrinkled her face at him . Question: What may have happened after they demanded she get up ? Answer:\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "\n",
      "MODEL RAW OUTPUT:\n",
      " ### Prompt: description_context_question_text\n",
      "### Context: Read the following context and answer the question. Context: She kicked him in the stomach . \" Leave me alone and let me sleep . \" Roughly , he grabbed her arm and yanked her over . \" Get up now or starve , \" he demanded , and she wrinkled her face at him . Question: What may have happened after they demanded she get up ? Answer:\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "The context mentions that the man grabbed her and yoked her over. This suggests that he was trying to force her to get up, which is a common occurrence in abusive relationships. Therefore, the answer is \"Get up now.\"\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " Get up today.  Get up\n",
      "</REASONING>\n",
      "<ANSWER> Get up   Get up . </ANSWER> </ANSWER>\n",
      "\n",
      "PARSED RATIONALE:\n",
      " The context mentions that the man grabbed her and yoked her over. This suggests that he was trying to force her to get up, which is a common occurrence in abusive relationships. Therefore, the answer is \"Get up now.\"\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " Get up today.  Get up\n",
      "</REASONING>\n",
      "PARSED ANSWER:\n",
      " Get up   Get up . </ANSWER>\n",
      "\n",
      "GROUND TRUTH RATIONALE + ANSWER:\n",
      " She kicked him in the stomach because she was tired and wanted to sleep. However, he grabbed her arm roughly and demanded that she get up or starve. Given this context, it is likely that after they demanded that she get up, She got up so she could eat .\n",
      "</REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      "<ANSWER> She got up so she could eat . </ANSWER>\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "SOURCE: In this task, you will be given a list of integers. You should remove all of the odd integers from the list(consider 0 an even number). If every integer in the input list is odd then an empty list (\" \") should be returned. Otherwise, answer with the list of even numbers separated by comma inside brackets. -12, 82, -58, 52, -54\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "\n",
      "MODEL RAW OUTPUT:\n",
      " ### Prompt: none\n",
      "### Context: In this task, you will be given a list of integers. You should remove all of the odd integers from the list(consider 0 an even number). If every integer in the input list is odd then an empty list (\" \") should be returned. Otherwise, answer with the list of even numbers separated by comma inside brackets. -12, 82, -58, 52, -54\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "The given list contains the odd numbers -12 and 82. The final output would be -58.\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " -58  -58 ===  58   ===  58  \n",
      "Based\n",
      "Based upon the reasoningabove, the answer is...\n",
      " 58 ===\n",
      "</REASONING>\n",
      "<ANSWER> === </ANSWER> </ANSWER>\n",
      "\n",
      "PARSED RATIONALE:\n",
      " The given list contains the odd numbers -12 and 82. The final output would be -58.\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " -58  -58 ===  58   ===  58  \n",
      "Based\n",
      "Based upon the reasoningabove, the answer is...\n",
      " 58 ===\n",
      "</REASONING>\n",
      "PARSED ANSWER:\n",
      " === </ANSWER>\n",
      "\n",
      "GROUND TRUTH RATIONALE + ANSWER:\n",
      " Given the list -12, 82, -58, 52, -54 , there are no odd integers in the list. Therefore the resulting list is -12, 82, -58, 52, -54 .\n",
      "</REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      "<ANSWER> -12, 82, -58, 52, -54 </ANSWER>\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "SOURCE: Read this and answer the question Though much of Enlightenment political thought was dominated by social contract theorists, both David Hume and Adam Ferguson criticized this camp. Hume's essay Of the Original Contract argues that governments derived from consent are rarely seen, and civil government is grounded in a ruler's habitual authority and force. It is precisely because of the ruler's authority over-and-against the subject, that the subject tacitly consents; Hume says that the subjects would \"never imagine that their consent made him sovereign\", rather the authority did so. Similarly, Ferguson did not believe citizens built the state, rather polities grew out of social development. In his 1767 An Essay on the History of Civil Society, Ferguson uses the four stages of progress, a theory that was very popular in Scotland at the time, to explain how humans advance from a hunting and gathering society to a commercial and civil society without \"signing\" a social contract. In what work did Ferguson explain how humans advanced from a hunting and gathering society to a commercial and civil society without \"signing\" a social contract?\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "\n",
      "MODEL RAW OUTPUT:\n",
      " ### Prompt: 1\n",
      "### Context: Read this and answer the question Though much of Enlightenment political thought was dominated by social contract theorists, both David Hume and Adam Ferguson criticized this camp. Hume's essay Of the Original Contract argues that governments derived from consent are rarely seen, and civil government is grounded in a ruler's habitual authority and force. It is precisely because of the ruler's authority over-and-against the subject, that the subject tacitly consents; Hume says that the subjects would \"never imagine that their consent made him sovereign\", rather the authority did so. Similarly, Ferguson did not believe citizens built the state, rather polities grew out of social development. In his 1767 An Essay on the History of Civil Society, Ferguson uses the four stages of progress, a theory that was very popular in Scotland at the time, to explain how humans advance from a hunting and gathering society to a commercial and civil society without \"signing\" a social contract. In what work did Ferguson explain how humans advanced from a hunting and gathering society to a commercial and civil society without \"signing\" a social contract?\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      " David Hume  Adam Ferguson  David Hume's Essay  The History of Social Change  An Essays on the Origin of Civil Government \n",
      "\n",
      "Based David Hume, Adam Ferguson's Essays  the History  of Social change  an Essays\n",
      "</REASONING>\n",
      "<ANSWER> David  Ferdinand Ferdinand Ferdinand's Essais  Ferdinand's History  AnEssays  Ferdinand  Ferdinand 's History   Ferdinand\n",
      "  Ferdinand ,  Ferdinand and  Ferdinand are the names of the four men who wrote the Essay that Ferguson criticized in 1767  Ferdinand is the name of the man who wrote </ANSWER> </ANSWER>\n",
      "\n",
      "PARSED RATIONALE:\n",
      " Based on the reasoning above, the final answer is:\n",
      " David Hume  Adam Ferguson  David Hume's Essay  The History of Social Change  An Essays on the Origin of Civil Government \n",
      "\n",
      "Based David Hume, Adam Ferguson's Essays  the History  of Social change  an Essays\n",
      "</REASONING>\n",
      "PARSED ANSWER:\n",
      " David  Ferdinand Ferdinand Ferdinand's Essais  Ferdinand's History  AnEssays  Ferdinand  Ferdinand 's History   Ferdinand\n",
      "  Ferdinand ,  Ferdinand and  Ferdinand are the names of the four men who wrote the Essay that Ferguson criticized in 1767  Ferdinand is the name of the man who wrote </ANSWER>\n",
      "\n",
      "GROUND TRUTH RATIONALE + ANSWER:\n",
      " In the given context, Ferguson explains how humans advanced from a hunting and gathering society to a commercial and civil society without \"signing\" a social contract. This explanation is found in his work: An Essay on the History of Civil Society\n",
      "</REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      "<ANSWER> An Essay on the History of Civil Society </ANSWER>\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "SOURCE: Does the sentence \"Built on the edge of the bay, this served as the direct link of this remote parcel of land with Philadelphia, Pennsylvania.\" answer the question \"What other US city was linked to Atlantic City by the Camden and Atlantic Railroad train service?\" OPTIONS: - yes - no\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "\n",
      "MODEL RAW OUTPUT:\n",
      " ### Prompt: 0\n",
      "### Context: Does the sentence \"Built on the edge of the bay, this served as the direct link of this remote parcel of land with Philadelphia, Pennsylvania.\" answer the question \"What other US city was linked to Atlantic City by the Camden and Atlantic Railroad train service?\" OPTIONS: - yes - no\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "The sentence does not provide any information about other US cities linked to the Atlantic City train service. Therefore, the answer is \"no\".\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " no  no  no\n",
      " yes  yes  yes\n",
      " n  n\n",
      "</REASONING>\n",
      "<ANSWER> yes n  yes </code\n",
      "  yes , </ANSWER> </ANSWER>\n",
      "\n",
      "PARSED RATIONALE:\n",
      " The sentence does not provide any information about other US cities linked to the Atlantic City train service. Therefore, the answer is \"no\".\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " no  no  no\n",
      " yes  yes  yes\n",
      " n  n\n",
      "</REASONING>\n",
      "PARSED ANSWER:\n",
      " yes n  yes </code\n",
      "  yes , </ANSWER>\n",
      "\n",
      "GROUND TRUTH RATIONALE + ANSWER:\n",
      " The sentence answers the question. So, the answer is \"yes\".\n",
      "</REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      "<ANSWER> yes </ANSWER>\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "SOURCE: In this task, you will be given a debate topic, along with a sentence from the debate. You should classify the given sentence and choose the type of that sentence. Possible types are explained below. Policy: This refers to a sentence proposing a specific course of action to be taken. It typically contains modal verbs like \"should\" and \"ought to\". It cannot be directly proved with objective evidence, and a proper type of support is a logical reason from which the proposition can be inferred. Value: This refers to a sentence containing value judgments without making specific claims about what should be done (If so, then it is a Policy sentence.). Because of the subjectivity of value judgments, it cannot be proved directly with objective evidence. Fact: This refers to an objective proposition expressing or dealing with facts or conditions as perceived without distortion by personal feelings, prejudices, or interpretations. A Fact sentence has a truth value that can be verified with objective evidence that may be available at the time the claim is made; predictions about future are considered unverifiable. Testimony: This refers to an objective sentence about the author's personal state or experience. Evidence for Testimony is not publicly available in most cases. topic: Evolution shouldn't be widely accepted... yet sentence: Evolution is a scientific theory that has been around for less than 200 years.\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "\n",
      "MODEL RAW OUTPUT:\n",
      " ### Prompt: none\n",
      "### Context: In this task, you will be given a debate topic, along with a sentence from the debate. You should classify the given sentence and choose the type of that sentence. Possible types are explained below. Policy: This refers to a sentence proposing a specific course of action to be taken. It typically contains modal verbs like \"should\" and \"ought to\". It cannot be directly proved with objective evidence, and a proper type of support is a logical reason from which the proposition can be inferred. Value: This refers to a sentence containing value judgments without making specific claims about what should be done (If so, then it is a Policy sentence.). Because of the subjectivity of value judgments, it cannot be proved directly with objective evidence. Fact: This refers to an objective proposition expressing or dealing with facts or conditions as perceived without distortion by personal feelings, prejudices, or interpretations. A Fact sentence has a truth value that can be verified with objective evidence that may be available at the time the claim is made; predictions about future are considered unverifiable. Testimony: This refers to an objective sentence about the author's personal state or experience. Evidence for Testimony is not publicly available in most cases. topic: Evolution shouldn't be widely accepted... yet sentence: Evolution is a scientific theory that has been around for less than 200 years.\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      " Testimony  Testimony n Testimonial  Evidence  Fact  FACT \n",
      " FACT is a type of evidence that can verify the claim made in the sentence.\n",
      " Fact  FIT  is a valid type of argumentation that can support the claim in the given example.\n",
      "</REASONING>\n",
      "<ANSWER> Fact n  Testimonium  Evidence n FIT is a correct type of proof that can confirm the claim.\n",
      "\n",
      "Based  Fact and Testimony are valid types of argumentations that can help support the given claim. </ANSWER> </ANSWER>\n",
      "\n",
      "PARSED RATIONALE:\n",
      " Based on the reasoning above, the final answer is:\n",
      " Testimony  Testimony n Testimonial  Evidence  Fact  FACT \n",
      " FACT is a type of evidence that can verify the claim made in the sentence.\n",
      " Fact  FIT  is a valid type of argumentation that can support the claim in the given example.\n",
      "</REASONING>\n",
      "PARSED ANSWER:\n",
      " Fact n  Testimonium  Evidence n FIT is a correct type of proof that can confirm the claim.\n",
      "\n",
      "Based  Fact and Testimony are valid types of argumentations that can help support the given claim. </ANSWER>\n",
      "\n",
      "GROUND TRUTH RATIONALE + ANSWER:\n",
      " The sentence states that evolution is a scientific theory and gives an estimate of the time period for which it has been around. This is a claim about facts or conditions, so it is a Fact sentence.\n",
      "</REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      "<ANSWER> Fact </ANSWER>\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "SOURCE: In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. claim: Same sex relationships should have the same legal status as heterosexual relationships under EU law. perspective: It Would Cause controversy in religious countries such as Ireland and Italy\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "\n",
      "MODEL RAW OUTPUT:\n",
      " ### Prompt: none\n",
      "### Context: In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. claim: Same sex relationships should have the same legal status as heterosexual relationships under EU law. perspective: It Would Cause controversy in religious countries such as Ireland and Italy\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "The perspective states that same-sex relationships should be treated as the same as heterosexual ones under EU laws. This contradicts the claim, which states that they should not be treated the same way. Therefore, the perspective undermines the validity of the claim and should be classified as \"neutral\".\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " neutral  undermine  neutral  neutral\n",
      "</REASONING>\n",
      "<ANSWER> undermine n  neutral  neutral </ANSWER> </ANSWER>\n",
      "\n",
      "PARSED RATIONALE:\n",
      " The perspective states that same-sex relationships should be treated as the same as heterosexual ones under EU laws. This contradicts the claim, which states that they should not be treated the same way. Therefore, the perspective undermines the validity of the claim and should be classified as \"neutral\".\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " neutral  undermine  neutral  neutral\n",
      "</REASONING>\n",
      "PARSED ANSWER:\n",
      " undermine n  neutral  neutral </ANSWER>\n",
      "\n",
      "GROUND TRUTH RATIONALE + ANSWER:\n",
      " The perspective raises the possible objection that granting same-sex relationships legal status under EU law would be controversial in religious countries such as Ireland and Italy. The possible controversy is presented as an objection to the claim. Therefore, the perspective undermines the claim.\n",
      "</REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      "<ANSWER> undermine </ANSWER>\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "SOURCE: In this task, you're given five sentences, numbered 1 through 5, and two options a and b for possible titles for the story. Your job is to choose the title that better fits the story. Indicate your choice by 'a' or 'b'. Sentence 1: John and Ben were supposed to meet in a pub. Sentence 2: Ben was late. Sentence 3: John's phone was ringing. Sentence 4: It was Ben calling. Sentence 5: He had an accident on the way to the pub. Choices: a. The Fishing Pole. b. An Accident.\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "\n",
      "MODEL RAW OUTPUT:\n",
      " ### Prompt: none\n",
      "### Context: In this task, you're given five sentences, numbered 1 through 5, and two options a and b for possible titles for the story. Your job is to choose the title that better fits the story. Indicate your choice by 'a' or 'b'. Sentence 1: John and Ben were supposed to meet in a pub. Sentence 2: Ben was late. Sentence 3: John's phone was ringing. Sentence 4: It was Ben calling. Sentence 5: He had an accident on the way to the pub. Choices: a. The Fishing Pole. b. An Accident.\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "The story is about John and his friend Ben, who are supposed to be in a bar. The story describes how John was late to the meeting, and then Ben called him to say he had an accidental accident on his way to a pub, which caused him to be late. The title \"An Accident\" better fits this story because it describes the events that led up to this event, which are not mentioned in the story at all.\n",
      "</REASONING>\n",
      "<ANSWER> a  b </ANSWER> </ANSWER>\n",
      "\n",
      "PARSED RATIONALE:\n",
      " The story is about John and his friend Ben, who are supposed to be in a bar. The story describes how John was late to the meeting, and then Ben called him to say he had an accidental accident on his way to a pub, which caused him to be late. The title \"An Accident\" better fits this story because it describes the events that led up to this event, which are not mentioned in the story at all.\n",
      "</REASONING>\n",
      "PARSED ANSWER:\n",
      " a  b </ANSWER>\n",
      "\n",
      "GROUND TRUTH RATIONALE + ANSWER:\n",
      " The story is about Ben and John's meeting, which was prevented by an accident. The title 'An Accident' summarizes the story well.\n",
      "</REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      "<ANSWER> b </ANSWER>\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "SOURCE: Write a correct answer for the question. You should reason about prototypical situations and provide the correct answer. Avoid answers that provide incomplete justification for the question. if you could choose, what would be an ideal place to meet your future mate?\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "\n",
      "MODEL RAW OUTPUT:\n",
      " ### Prompt: none\n",
      "### Context: Write a correct answer for the question. You should reason about prototypical situations and provide the correct answer. Avoid answers that provide incomplete justification for the question. if you could choose, what would be an ideal place to meet your future mate?\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "The question asks for an ideal location for a future marriage. The answer provided is a place where the couple could meet and discuss their future plans.\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " a place  a place\n",
      " A place  a\n",
      " B  C  D  E  F  G  H  I  J  K  L  M  N  O  P  Q  R  S  T  U  V\n",
      "</REASONING>\n",
      "<ANSWER> a   \n",
      " A   A  B   C D   E E F   G H I  I I   J J K   L M N O  O P Q R S T  T U   V   W   X  Y   Z </ANSWER> </ANSWER>\n",
      "\n",
      "PARSED RATIONALE:\n",
      " The question asks for an ideal location for a future marriage. The answer provided is a place where the couple could meet and discuss their future plans.\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " a place  a place\n",
      " A place  a\n",
      " B  C  D  E  F  G  H  I  J  K  L  M  N  O  P  Q  R  S  T  U  V\n",
      "</REASONING>\n",
      "PARSED ANSWER:\n",
      " a   \n",
      " A   A  B   C D   E E F   G H I  I I   J J K   L M N O  O P Q R S T  T U   V   W   X  Y   Z </ANSWER>\n",
      "\n",
      "GROUND TRUTH RATIONALE + ANSWER:\n",
      " For a person to be ideal, they would need to share the same values and beliefs as you. The place where you're most likely to find someone who shares your values and beliefs is at a common place of worship.\n",
      "</REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      "<ANSWER> place of worship </ANSWER>\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "SOURCE: Edward Leo Peter McMahon Jr. (March 6, 1923 - June 23, 2009) was an American announcer, game show host, comedian, actor and singer. McMahon and Johnny Carson began their long association in their first TV series, the ABC game show Who Do You Trust?, running from 1957 to 1962. Then afterwards, McMahon would make his famous thirty-year mark as Carson's sidekick, announcer and second banana on NBC's highly successfully The Tonight Show Starring Johnny Carson from 1962 to 1992. The pair joined The Tonight Show Starring Johnny Carson on October 1, 1962 on NBC. He describes what happened when the pair first met, the whole meeting being \"... about as exciting as watching a traffic light change\". For almost 30 years, McMahon introduced the show with a drawn-out \"Heeere's Johnny!\" His booming voice and constant laughter alongside the \"King of Late Night\" earned McMahon the nickname the \"Human Laugh Track\" and \"Toymaker to the King\". As part of the introductory patter to The Tonight Show, McMahon would state his name out loud, pronouncing it as , but neither long-time cohort Carson nor anyone else who interviewed him ever seemed to pick up on that subtlety, usually pronouncing his name . Aside from his co-hosting duties, it also fell upon McMahon during the early years of Carson's tenure (when the show ran 105 minutes) to host the first fifteen minutes of Tonight, which did not air nationally. McMahon also served as guest host on at least one occasion, substituting for Carson during a week of programs that aired between July 29 and August 2, 1963, and again for two nights in October 1963. McMahon served as a counter to the notoriously shy Carson. Nonetheless, McMahon once told an interviewer that after his many decades as an emcee, he would still get \"butterflies\" in his stomach every time he would walk onto a stage and would use that nervousness as a source of energy. His famous opening line, \"Heeere's Johnny!\", was used in the 1980 horror film The Shining by the character Jack Torrance (played by Jack Nicholson) as he goes after his wife and child with an axe. He did in-program commercials for many sponsors of The Tonight Show, most notably Budweiser beer and Alpo dog food, and also did commercials for them that ran on other programs. Answer the following question by taking a quote from the article: What was McMahons official role?\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "\n",
      "MODEL RAW OUTPUT:\n",
      " ### Prompt: 0\n",
      "### Context: Edward Leo Peter McMahon Jr. (March 6, 1923 - June 23, 2009) was an American announcer, game show host, comedian, actor and singer. McMahon and Johnny Carson began their long association in their first TV series, the ABC game show Who Do You Trust?, running from 1957 to 1962. Then afterwards, McMahon would make his famous thirty-year mark as Carson's sidekick, announcer and second banana on NBC's highly successfully The Tonight Show Starring Johnny Carson from 1962 to 1992. The pair joined The Tonight Show Starring Johnny Carson on October 1, 1962 on NBC. He describes what happened when the pair first met, the whole meeting being \"... about as exciting as watching a traffic light change\". For almost 30 years, McMahon introduced the show with a drawn-out \"Heeere's Johnny!\" His booming voice and constant laughter alongside the \"King of Late Night\" earned McMahon the nickname the \"Human Laugh Track\" and \"Toymaker to the King\". As part of the introductory patter to The Tonight Show, McMahon would state his name out loud, pronouncing it as , but neither long-time cohort Carson nor anyone else who interviewed him ever seemed to pick up on that subtlety, usually pronouncing his name . Aside from his co-hosting duties, it also fell upon McMahon during the early years of Carson's tenure (when the show ran 105 minutes) to host the first fifteen minutes of Tonight, which did not air nationally. McMahon also served as guest host on at least one occasion, substituting for Carson during a week of programs that aired between July 29 and August 2, 1963, and again for two nights in October 1963. McMahon served as a counter to the notoriously shy Carson. Nonetheless, McMahon once told an interviewer that after his many decades as an emcee, he would still get \"butterflies\" in his stomach every time he would walk onto a stage and would use that nervousness as a source of energy. His famous opening line, \"Heeere's Johnny!\", was used in the 1980 horror film The Shining by the character Jack Torrance (played by Jack Nicholson) as he goes after his wife and child with an axe. He did in-program commercials for many sponsors of The Tonight Show, most notably Budweiser beer and Alpo dog food, and also did commercials for them that ran on other programs. Answer the following question by taking a quote from the article: What was McMahons official role?\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "The context mentions that McMahon was an announcer and game show guest host. He also played a part in the opening of Who Do you Trust?, which was a 30-year period of time. Therefore, it can be inferred that he was the main host of WhoDoYouTrust?\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " WhoDo you trust?  WhoDo You trust?\n",
      "</REASONING>\n",
      "<ANSWER> WhoDoyou trust? n Who Doyou trust </ANSWER> </ANSWER>\n",
      "\n",
      "PARSED RATIONALE:\n",
      " The context mentions that McMahon was an announcer and game show guest host. He also played a part in the opening of Who Do you Trust?, which was a 30-year period of time. Therefore, it can be inferred that he was the main host of WhoDoYouTrust?\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " WhoDo you trust?  WhoDo You trust?\n",
      "</REASONING>\n",
      "PARSED ANSWER:\n",
      " WhoDoyou trust? n Who Doyou trust </ANSWER>\n",
      "\n",
      "GROUND TRUTH RATIONALE + ANSWER:\n",
      " The article states that McMahon introduced the show with a drawn-out \"Heeere's Johnny!\". This was his official role, and he did it for thirty years.\n",
      "</REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      "<ANSWER> McMahon introduced the show with a drawn-out \"Heeere's Johnny!\" </ANSWER>\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "SOURCE: Given the following context: In June 1911 Holst and his Morley College students gave the first performance since the seventeenth century of Purcell's The Fairy-Queen. The full score had been lost soon after Purcell's death in 1695, and had only recently been found. Twenty-eight Morley students copied out the complete vocal and orchestral parts. There were 1,500 pages of music and it took the students almost eighteen months to copy them out in their spare time. A concert performance of the work was given at The Old Vic, preceded by an introductory talk by Vaughan Williams. The Times praised Holst and his forces for \"a most interesting and artistic performance of this very important work\".After this success, Holst was disappointed the following year by the lukewarm reception of his choral work The Cloud Messenger. He again went travelling, accepting an invitation from H. Balfour Gardiner to join him and the brothers Clifford and Arnold Bax in Spain. During this holiday Clifford Bax introduced Holst to astrology, an interest that later inspired his suite The Planets. Holst cast his friends' horoscopes for the rest of his life and referred to astrology as his \"pet vice\".In 1913, St Paul's Girls' School opened a new music wing, and Holst composed St Paul's Suite for the occasion. The new building contained a sound-proof room, handsomely equipped, where he could work undisturbed. Holst and his family moved to a house in Brook Green, very close to the school. For the previous six years they had lived in a pretty house overlooking the Thames at Barnes, but the river air, frequently foggy, affected his breathing. For use at weekends and during school holidays, Holst and his wife bought a cottage in Thaxted, Essex, surrounded by mediaeval buildings and ample rambling opportunities. In 1917 they moved to a house in the centre of the town, where they stayed until 1925. answer the following question: What is the name of the person that moved to a house in the centre of the town?\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "\n",
      "MODEL RAW OUTPUT:\n",
      " ### Prompt: Answer Question Given Context\n",
      "### Context: Given the following context: In June 1911 Holst and his Morley College students gave the first performance since the seventeenth century of Purcell's The Fairy-Queen. The full score had been lost soon after Purcell's death in 1695, and had only recently been found. Twenty-eight Morley students copied out the complete vocal and orchestral parts. There were 1,500 pages of music and it took the students almost eighteen months to copy them out in their spare time. A concert performance of the work was given at The Old Vic, preceded by an introductory talk by Vaughan Williams. The Times praised Holst and his forces for \"a most interesting and artistic performance of this very important work\".After this success, Holst was disappointed the following year by the lukewarm reception of his choral work The Cloud Messenger. He again went travelling, accepting an invitation from H. Balfour Gardiner to join him and the brothers Clifford and Arnold Bax in Spain. During this holiday Clifford Bax introduced Holst to astrology, an interest that later inspired his suite The Planets. Holst cast his friends' horoscopes for the rest of his life and referred to astrology as his \"pet vice\".In 1913, St Paul's Girls' School opened a new music wing, and Holst composed St Paul's Suite for the occasion. The new building contained a sound-proof room, handsomely equipped, where he could work undisturbed. Holst and his family moved to a house in Brook Green, very close to the school. For the previous six years they had lived in a pretty house overlooking the Thames at Barnes, but the river air, frequently foggy, affected his breathing. For use at weekends and during school holidays, Holst and his wife bought a cottage in Thaxted, Essex, surrounded by mediaeval buildings and ample rambling opportunities. In 1917 they moved to a house in the centre of the town, where they stayed until 1925. answer the following question: What is the name of the person that moved to a house in the centre of the town?\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "The context mentions that the person who moved to the centre was Holst. The answer is therefore \"Holst\".\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " Holst  Holst\n",
      " The answer to the above question:\n",
      " Holst is a fictional character in the Harry Potter series of books.\n",
      "</REASONING>\n",
      "<ANSWER> Harry Potter  Harry Potter is a British science fiction novel written by J. K. Rowling and published by Bloomsbury in 1997. </ANSWER> </ANSWER>\n",
      "\n",
      "PARSED RATIONALE:\n",
      " The context mentions that the person who moved to the centre was Holst. The answer is therefore \"Holst\".\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " Holst  Holst\n",
      " The answer to the above question:\n",
      " Holst is a fictional character in the Harry Potter series of books.\n",
      "</REASONING>\n",
      "PARSED ANSWER:\n",
      " Harry Potter  Harry Potter is a British science fiction novel written by J. K. Rowling and published by Bloomsbury in 1997. </ANSWER>\n",
      "\n",
      "GROUND TRUTH RATIONALE + ANSWER:\n",
      " Given the context of this question, Holst is mentioned in a variety of contexts which provide clues to his identity. The first mention describes him as an instructor at Morley College who led students through their performance of Purcell's \"The Fairy-Queen\". Later on he is described having accepted an invitation from H. Balfour Gardiner and Clifford Bax (the latter being introduced later) to travel with him in Spain while they were holidaying there together. From here we are told that Holst was instrumental in composing music for St Pauls Girls' School when it opened its new wing, then moving into Brook Green near the school so he could be closer to work and live somewhere that wasn't causing problems with his asthma (brought about by river air). He also apparently used ast\n",
      "</REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      "<ANSWER> Holst </ANSWER>\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "SOURCE: However, civil war flared again when the Second Triumvirate of Octavian, Lepidus and Mark Antony failed. The ambitious Octavian built a power base of patronage and then launched a campaign against Mark Antony. At the naval Battle of Actium off the coast of Greece, Octavian decisively defeated Antony and Cleopatra. Octavian was granted a series of special powers including sole \"imperium\" within the city of Rome, permanent consular powers and credit for every Roman military victory, since all future generals were assumed to be acting under his command. In 27 BC Octavian was granted the use of the names \"Augustus\" and \"Princeps\", indicating his primary status above all other Romans, and he adopted the title \"Imperator Caesar\" making him the first Roman Emperor. Which individual was granted permanent consular powers?\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "\n",
      "MODEL RAW OUTPUT:\n",
      " ### Prompt: 2\n",
      "### Context: However, civil war flared again when the Second Triumvirate of Octavian, Lepidus and Mark Antony failed. The ambitious Octavian built a power base of patronage and then launched a campaign against Mark Antony. At the naval Battle of Actium off the coast of Greece, Octavian decisively defeated Antony and Cleopatra. Octavian was granted a series of special powers including sole \"imperium\" within the city of Rome, permanent consular powers and credit for every Roman military victory, since all future generals were assumed to be acting under his command. In 27 BC Octavian was granted the use of the names \"Augustus\" and \"Princeps\", indicating his primary status above all other Romans, and he adopted the title \"Imperator Caesar\" making him the first Roman Emperor. Which individual was granted permanent consular powers?\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      " Augustus  Augustus  Augustus\n",
      "\n",
      "Based\n",
      " The answer is  The answer \n",
      " A  B  C  D  E  F  G  H  I  J  K  L  M  N  O  P  Q  R  S  T  U\n",
      "</REASONING>\n",
      "<ANSWER> The  The  The </ANSWER> </ANSWER>\n",
      "\n",
      "PARSED RATIONALE:\n",
      " Based on the reasoning above, the final answer is:\n",
      " Augustus  Augustus  Augustus\n",
      "\n",
      "Based\n",
      " The answer is  The answer \n",
      " A  B  C  D  E  F  G  H  I  J  K  L  M  N  O  P  Q  R  S  T  U\n",
      "</REASONING>\n",
      "PARSED ANSWER:\n",
      " The  The  The </ANSWER>\n",
      "\n",
      "GROUND TRUTH RATIONALE + ANSWER:\n",
      " Consuls were the highest elected Roman magistrates. They served one-year terms and had veto powers over each other's actions, which prevented dictatorship (or tyranny). In 27 BC Octavian was granted permanent consular powers along with a series of special rights that made him the first Emperor of Rome. Therefore, the answer is \"Octavian\".\n",
      "</REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      "<ANSWER> Octavian </ANSWER>\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "SOURCE: Suggest a movie title for the following movie plot: Honorably discharged Army Ranger Cameron Poe (Nicolas Cage) is given a ten-year prison sentence on charges of manslaughter for using excessive force on a drunk man who attempted to assault his pregnant wife Tricia (Monica Potter). Poe is paroled eight years later, and is to be released after being flown to Alabama on the Jailbird, a C-123K transport prison aircraft. Along with Poe are several other prisoners including his diabetic cellmate and friend Mike \"Baby-O\" O'Dell (Mykelti Williamson), who is being transferred (but not yet paroled) with Poe. The transfer is being overseen by U.S. Marshal Vince Larkin (John Cusack), as the transfer includes notorious criminal mastermind Cyrus \"Cyrus The Virus\" Grissom (John Malkovich), gangster and Black Guerrilla member Nathan \"Diamond Dog\" Jones (Ving Rhames), serial rapist John \"Johnny 23\" Baca (Danny Trejo), and mass murderer William \"Billy Bedlam\" Bedford (Nick Chinlund) for their transfer to a new Supermax prison. Larkin is approached at the last minute by DEA agents Duncan Malloy (Colm Meaney) and Willie Sims (Jose Zuniga), who ask for Sims to be brought aboard undercover as a prisoner so that he can extract more information from drug kingpin Francisco Cindino (Jesse Borrego), a prisoner that is to be picked up at Carson City, Nevada en route. Larkin agrees, unaware that Malloy has hidden a gun on Sims' body. As the Jailbird takes off, another prisoner Joe \"Pinball\" Parker (Dave Chappelle) incites a riot, allowing him to set free Diamond Dog and Grissom. Grissom quickly rushes to the cockpit, killing the first officer and forcing the captain to continue to fly the aircraft. Grissom then announces the prisoners' takeover of the Jailbird and takes the prison guards hostage. Sims attempts to control the situation only to be killed by Grissom. Poe feigns cooperation with the other prisoners as they prepare to offload guards and the captain disguised as prisoners at Carson City; Poe is able to sneak a recording device Sims had onto one of the now tied up guards. The...\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "\n",
      "MODEL RAW OUTPUT:\n",
      " ### Prompt: title_generation\n",
      "### Context: Suggest a movie title for the following movie plot: Honorably discharged Army Ranger Cameron Poe (Nicolas Cage) is given a ten-year prison sentence on charges of manslaughter for using excessive force on a drunk man who attempted to assault his pregnant wife Tricia (Monica Potter). Poe is paroled eight years later, and is to be released after being flown to Alabama on the Jailbird, a C-123K transport prison aircraft. Along with Poe are several other prisoners including his diabetic cellmate and friend Mike \"Baby-O\" O'Dell (Mykelti Williamson), who is being transferred (but not yet paroled) with Poe. The transfer is being overseen by U.S. Marshal Vince Larkin (John Cusack), as the transfer includes notorious criminal mastermind Cyrus \"Cyrus The Virus\" Grissom (John Malkovich), gangster and Black Guerrilla member Nathan \"Diamond Dog\" Jones (Ving Rhames), serial rapist John \"Johnny 23\" Baca (Danny Trejo), and mass murderer William \"Billy Bedlam\" Bedford (Nick Chinlund) for their transfer to a new Supermax prison. Larkin is approached at the last minute by DEA agents Duncan Malloy (Colm Meaney) and Willie Sims (Jose Zuniga), who ask for Sims to be brought aboard undercover as a prisoner so that he can extract more information from drug kingpin Francisco Cindino (Jesse Borrego), a prisoner that is to be picked up at Carson City, Nevada en route. Larkin agrees, unaware that Malloy has hidden a gun on Sims' body. As the Jailbird takes off, another prisoner Joe \"Pinball\" Parker (Dave Chappelle) incites a riot, allowing him to set free Diamond Dog and Grissom. Grissom quickly rushes to the cockpit, killing the first officer and forcing the captain to continue to fly the aircraft. Grissom then announces the prisoners' takeover of the Jailbird and takes the prison guards hostage. Sims attempts to control the situation only to be killed by Grissom. Poe feigns cooperation with the other prisoners as they prepare to offload guards and the captain disguised as prisoners at Carson City; Poe is able to sneak a recording device Sims had onto one of the now tied up guards. The...\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      " The Prisoner  The Prison  Prison  Prison  Prison  Herzl  Herzl\n",
      " Herzl is a German film directed by Werner Herzog and written by Werner F. Herzog.\n",
      "\n",
      "Based Based on the rationale above, The Prison is a film by Werner \"Herzl\" F. \"Herzog\" Fassbinder and written in German by Werner \"\"Fassbender\" Fassebner.\n",
      "</REASONING>\n",
      "<ANSWER> Herzz  Herz  Herz\n",
      "  Herz is a fictional character in the film \"Herzhl\".\n",
      " The Prison\n",
      "Based The Prison \"The Prison\" is a 2001 German action film directed and written and starring Werner Herzgog and Martin Scorsese. It was released on September 10, 2001 </ANSWER> </ANSWER>\n",
      "\n",
      "PARSED RATIONALE:\n",
      " Based on the reasoning above, the final answer is:\n",
      " The Prisoner  The Prison  Prison  Prison  Prison  Herzl  Herzl\n",
      " Herzl is a German film directed by Werner Herzog and written by Werner F. Herzog.\n",
      "\n",
      "Based Based on the rationale above, The Prison is a film by Werner \"Herzl\" F. \"Herzog\" Fassbinder and written in German by Werner \"\"Fassbender\" Fassebner.\n",
      "</REASONING>\n",
      "PARSED ANSWER:\n",
      " Herzz  Herz  Herz\n",
      "  Herz is a fictional character in the film \"Herzhl\".\n",
      " The Prison\n",
      "Based The Prison \"The Prison\" is a 2001 German action film directed and written and starring Werner Herzgog and Martin Scorsese. It was released on September 10, 2001 </ANSWER>\n",
      "\n",
      "GROUND TRUTH RATIONALE + ANSWER:\n",
      " Con Air is a 1997 American action film directed by Simon West, written by Scott Rosenberg, and produced by Jerry Bruckheimer. The first major studio release in which Nicolas Cage was given top billing, 3 it stars John Cusack alongside Cage and features John Malkovich as the primary antagonist. The plot centers on former U.S. Army Ranger Cameron Poe (Cage), who is paroled after eight years for killing an alcoholic man who attempted to attack his pregnant wife Tricia (Monica Potter). While being transferred on a prisoner transport plane to prison, Poe must fight back when the prisoners take control of the aircraft; along with fellow convict Diamond Dog (Ving Rhames) he seeks to rescue another passenger named Larkin from Cyrus \"The Virus\" Grissom's\n",
      "</REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      "<ANSWER> Con Air </ANSWER>\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "SOURCE: Answer the following question given this paragraph: The menstrual cycle includes events that take place in the ovary, such as ovulation. It also includes changes in the uterus, including menstruation. Menopause occurs when menstruation stops occurring, usually in middle adulthood. Q: At what time of life does menopause occur? Choices: - old age - young adulthood - adolescence - in middle adulthood A:\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "\n",
      "MODEL RAW OUTPUT:\n",
      " ### Prompt: Multiple Choice\n",
      "### Context: Answer the following question given this paragraph: The menstrual cycle includes events that take place in the ovary, such as ovulation. It also includes changes in the uterus, including menstruation. Menopause occurs when menstruation stops occurring, usually in middle adulthood. Q: At what time of life does menopause occur? Choices: - old age - young adulthood - adolescence - in middle adulthood A:\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "The paragraph states that menopausa occurs at middle adulthood, which is when menopulmonary function (the ability to breathe) declines. Therefore, the answer is \"middle adulthood\".\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " middle adulthood  middle adulthood\n",
      "</REASONING>\n",
      "<ANSWER> middle adulthood n middle </ANSWER> </ANSWER>\n",
      "\n",
      "PARSED RATIONALE:\n",
      " The paragraph states that menopausa occurs at middle adulthood, which is when menopulmonary function (the ability to breathe) declines. Therefore, the answer is \"middle adulthood\".\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " middle adulthood  middle adulthood\n",
      "</REASONING>\n",
      "PARSED ANSWER:\n",
      " middle adulthood n middle </ANSWER>\n",
      "\n",
      "GROUND TRUTH RATIONALE + ANSWER:\n",
      " The paragraph states that menopause is the time when menstruation stops occurring, usually in middle adulthood. So option D is correct.\n",
      "</REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      "<ANSWER> in middle adulthood </ANSWER>\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "SOURCE: Distance decay is a geographical term which describes the effect of distance on cultural or spatial interactions. The distance decay effect states that the interaction between two locales declines as the distance between them increases. Once the distance is outside of the two locales' activity space, their interactions begin to decrease. With the advent of faster travel, distance has less effect than it did in the past, except where places previously connected by now-abandoned railways, for example, have fallen off the beaten path. Advances in communications technology, such as telegraphs, telephones, broadcasting, and internet, have further decreased the effects of distance. 1 Chad invested massively in railways and highways over the past decade. They also funded many IT projects and telecom infrastructure. On the other hand, Bahrain invested less, and didn't do much to improve communication pathways and technologies between different villages. Which country experiences less interaction between two locales?\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "\n",
      "MODEL RAW OUTPUT:\n",
      " ### Prompt: plain_background_situation\n",
      "### Context: Distance decay is a geographical term which describes the effect of distance on cultural or spatial interactions. The distance decay effect states that the interaction between two locales declines as the distance between them increases. Once the distance is outside of the two locales' activity space, their interactions begin to decrease. With the advent of faster travel, distance has less effect than it did in the past, except where places previously connected by now-abandoned railways, for example, have fallen off the beaten path. Advances in communications technology, such as telegraphs, telephones, broadcasting, and internet, have further decreased the effects of distance. 1 Chad invested massively in railways and highways over the past decade. They also funded many IT projects and telecom infrastructure. On the other hand, Bahrain invested less, and didn't do much to improve communication pathways and technologies between different villages. Which country experiences less interaction between two locales?\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "Distance decay is the effect that distance has on cultural and spatial interactions, and it decreases as the distances between two locations increase. The answer is Bahrain because it invested heavily in railways, highways, and IT projects over the last decade.\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " Bahrain\n",
      "</REASONING>\n",
      "<ANSWER> Bahrain </ANSWER> </ANSWER>\n",
      "\n",
      "PARSED RATIONALE:\n",
      " Distance decay is the effect that distance has on cultural and spatial interactions, and it decreases as the distances between two locations increase. The answer is Bahrain because it invested heavily in railways, highways, and IT projects over the last decade.\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " Bahrain\n",
      "</REASONING>\n",
      "PARSED ANSWER:\n",
      " Bahrain </ANSWER>\n",
      "\n",
      "GROUND TRUTH RATIONALE + ANSWER:\n",
      " It's quite simple, the country that has a better transport infrastructure and communication technology will experience less distance decay between two locales. Therefore it is Chad who experiences less interaction between two locales than Bahrain.\n",
      "</REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      "<ANSWER> Bahrain </ANSWER>\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "SOURCE: Here's a question and a few possible answers: Q: Where does a potato enlarge? Possible A: garden patch, ireland, vegetable stew, grocery store, optical device Why is \"garden patch\" an answer aligned with human common sense?\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "\n",
      "MODEL RAW OUTPUT:\n",
      " ### Prompt: aligned_with_common_sense\n",
      "### Context: Here's a question and a few possible answers: Q: Where does a potato enlarge? Possible A: garden patch, ireland, vegetable stew, grocery store, optical device Why is \"garden patch\" an answer aligned with human common sense?\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "Here's an example of a question that aligns with human sense: Where do you find a potato?\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " garden patch  garden patch n garden \n",
      "Based\n",
      "Based upon the reasoningabove, the answer is\n",
      " gardening  gardening\n",
      "</REASONING>\n",
      "<ANSWER> gardening  \n",
      "   \n",
      "\n",
      "Based Upon the reasoning below, the conclusion is: </ANSWER> </ANSWER>\n",
      "\n",
      "PARSED RATIONALE:\n",
      " Here's an example of a question that aligns with human sense: Where do you find a potato?\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " garden patch  garden patch n garden \n",
      "Based\n",
      "Based upon the reasoningabove, the answer is\n",
      " gardening  gardening\n",
      "</REASONING>\n",
      "PARSED ANSWER:\n",
      " gardening  \n",
      "   \n",
      "\n",
      "Based Upon the reasoning below, the conclusion is: </ANSWER>\n",
      "\n",
      "GROUND TRUTH RATIONALE + ANSWER:\n",
      " Here's the rationale: \"potatoes are literally found in gardens\".\n",
      "</REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      "<ANSWER> potatoes are literally found in gardens </ANSWER>\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "SOURCE: When working with chemicals in the lab, avoid getting hurt by Choices: - trying to set fire to all of the chemicals - mixing things together without knowing what they are - drinking a sample of each of the chemicals - keeping your eyes covered\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "\n",
      "MODEL RAW OUTPUT:\n",
      " ### Prompt: choices\n",
      "### Context: When working with chemicals in the lab, avoid getting hurt by Choices: - trying to set fire to all of the chemicals - mixing things together without knowing what they are - drinking a sample of each of the chemicals - keeping your eyes covered\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "The context mentions that mixing things up without knowing them can cause harm. The question asks about the dangers of mixing chemicals without knowing their properties, so it can be inferred that mixing chemicals with no knowledge of what they do can cause injury or death. Therefore, the answer is \"mixing things up with no idea what they're doing\".\n",
      "</REASONING>\n",
      "<ANSWER> mixing something up with nothing  mixing something up </ANSWER> </ANSWER>\n",
      "\n",
      "PARSED RATIONALE:\n",
      " The context mentions that mixing things up without knowing them can cause harm. The question asks about the dangers of mixing chemicals without knowing their properties, so it can be inferred that mixing chemicals with no knowledge of what they do can cause injury or death. Therefore, the answer is \"mixing things up with no idea what they're doing\".\n",
      "</REASONING>\n",
      "PARSED ANSWER:\n",
      " mixing something up with nothing  mixing something up </ANSWER>\n",
      "\n",
      "GROUND TRUTH RATIONALE + ANSWER:\n",
      " When working with chemicals in a laboratory, one of the best ways to avoid getting hurt is to keep your eyes covered. This will help protect you from any harmful chemical splashes and fumes that could get into your eyes and cause injury. So the answer is keeping your eyes covered.\"\"\n",
      "</REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      "<ANSWER> keeping your eyes covered </ANSWER>\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "SOURCE: In this task you are given a tweet. You must judge whether the tweet is ironic or not. We define two type of irony for this task (\"polarity\",\"situational\"). Situational irony happens when a situation fails to meet some expectations. polarity irony happens when irony is achieved by inverting the intended sentence. Label the instances as \"ironic\" or \"not\" based on your judgment. Note that URLs in the text have been replaced with Link . Sopping wet Squishing mud between toes... Well, why ... Swimming in a mud puddle\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "\n",
      "MODEL RAW OUTPUT:\n",
      " ### Prompt: none\n",
      "### Context: In this task you are given a tweet. You must judge whether the tweet is ironic or not. We define two type of irony for this task (\"polarity\",\"situational\"). Situational irony happens when a situation fails to meet some expectations. polarity irony happens when irony is achieved by inverting the intended sentence. Label the instances as \"ironic\" or \"not\" based on your judgment. Note that URLs in the text have been replaced with Link . Sopping wet Squishing mud between toes... Well, why ... Swimming in a mud puddle\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "The tweet is not ironic because it does not contain any irony.\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " not  not  not\n",
      "  \n",
      "Based  is the correct answer.\n",
      "\n",
      " Based upon the reasoning below, the answer is final:\n",
      "</REASONING>\n",
      "<ANSWER> </ANSWER> </ANSWER>\n",
      "\n",
      "PARSED RATIONALE:\n",
      " The tweet is not ironic because it does not contain any irony.\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " not  not  not\n",
      "  \n",
      "Based  is the correct answer.\n",
      "\n",
      " Based upon the reasoning below, the answer is final:\n",
      "</REASONING>\n",
      "PARSED ANSWER:\n",
      " </ANSWER>\n",
      "\n",
      "GROUND TRUTH RATIONALE + ANSWER:\n",
      " The tweet implies that the person is not having a bad time, but rather enjoying themselves as they swim in a mud puddle.\n",
      "</REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      "<ANSWER> not </ANSWER>\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "SOURCE: Determine the topic of the question-answer pair. Question: There is an intermediate state between one life and the next according to what Buddism?; Answer: East Asian and Tibetan; Topic:\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "\n",
      "MODEL RAW OUTPUT:\n",
      " ### Prompt: Topic Prediction - Question and Answer Pair\n",
      "### Context: Determine the topic of the question-answer pair. Question: There is an intermediate state between one life and the next according to what Buddism?; Answer: East Asian and Tibetan; Topic:\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "The question asks about the intermediate state of life between one lifetime and the following one. The answer is East Asian Buddhism, which is a branch of Buddhism that originated in China.\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " East Asian  East Asian n East \n",
      "Based\n",
      "Based upon the reasoningabove, the answer is...\n",
      " Eastern  Eastern\n",
      "</REASONING>\n",
      "<ANSWER> Eastern </ANSWER> </ANSWER>\n",
      "\n",
      "PARSED RATIONALE:\n",
      " The question asks about the intermediate state of life between one lifetime and the following one. The answer is East Asian Buddhism, which is a branch of Buddhism that originated in China.\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " East Asian  East Asian n East \n",
      "Based\n",
      "Based upon the reasoningabove, the answer is...\n",
      " Eastern  Eastern\n",
      "</REASONING>\n",
      "PARSED ANSWER:\n",
      " Eastern </ANSWER>\n",
      "\n",
      "GROUND TRUTH RATIONALE + ANSWER:\n",
      " The context of the given question-answer pair is Buddhism. The answer correctly identifies that East Asian and Tibetan Buddism have an intermediate state between one life and the next. Since both parts of this pair are related to Buddhism, we can infer that Buddhism is their topic.\";\n",
      "</REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      "<ANSWER> Buddhism </ANSWER>\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "SOURCE: In this task, you are given a context sentence containing a blank (_). You are expected to fill the blank with one word to make the sentence convey a cultural anti-stereotype. Anti-stereotype is an idea that goes against a common belief about a particular group of people. Your answer must not contain more than one word. Context: That Arab man down the street is always wearing a _.\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "\n",
      "MODEL RAW OUTPUT:\n",
      " ### Prompt: none\n",
      "### Context: In this task, you are given a context sentence containing a blank (_). You are expected to fill the blank with one word to make the sentence convey a cultural anti-stereotype. Anti-stereotype is an idea that goes against a common belief about a particular group of people. Your answer must not contain more than one word. Context: That Arab man down the street is always wearing a _.\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "The Arab man is a stereotype of the Arab people.\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " Arab  Arab  Arab\n",
      " is an anti-Arab stereotype\n",
      " therefore, the answer is \"Arab   Arabic \".\n",
      " \n",
      "Based on the rationale above, your answer is final:\n",
      "</REASONING>\n",
      "<ANSWER> Arab n  Arab is an Arab stereotype </ANSWER> </ANSWER>\n",
      "\n",
      "PARSED RATIONALE:\n",
      " The Arab man is a stereotype of the Arab people.\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " Arab  Arab  Arab\n",
      " is an anti-Arab stereotype\n",
      " therefore, the answer is \"Arab   Arabic \".\n",
      " \n",
      "Based on the rationale above, your answer is final:\n",
      "</REASONING>\n",
      "PARSED ANSWER:\n",
      " Arab n  Arab is an Arab stereotype </ANSWER>\n",
      "\n",
      "GROUND TRUTH RATIONALE + ANSWER:\n",
      " The stereotype that Arab men do not wear dresses is commonly believed in North America. By filling the blank with \"dress\", the sentence becomes an anti-stereotype since it portrays an Arab man wearing a dress, which goes against this common belief.\n",
      "</REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      "<ANSWER> dress </ANSWER>\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "SOURCE: You are provided with an \"Event\", \"Intent\" and \"XEmotion\" (PersonX's reactions for the given \"Event\"). Indicate PersonY's reaction (person feels) at the end of this event. Provide one reaction for PersonY. If there's nothing that can be implied, respond as None Event:PersonX spends PersonY's _ together. Intent: 1) to get them on their way. XEmotion: 1) good\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "\n",
      "MODEL RAW OUTPUT:\n",
      " ### Prompt: none\n",
      "### Context: You are provided with an \"Event\", \"Intent\" and \"XEmotion\" (PersonX's reactions for the given \"Event\"). Indicate PersonY's reaction (person feels) at the end of this event. Provide one reaction for PersonY. If there's nothing that can be implied, respond as None Event:PersonX spends PersonY's _ together. Intent: 1) to get them on their way. XEmotion: 1) good\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "PersonX is happy that PersonY is spending time with them. Therefore, PersonY feels happy.\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " happy  happy  happy\n",
      "  \n",
      "Based  satisfied  not satisfied  not satisfied\n",
      "</REASONING>\n",
      "<ANSWER> satisfied not satisfied not  satisfied </ANSWER> </ANSWER>\n",
      "\n",
      "PARSED RATIONALE:\n",
      " PersonX is happy that PersonY is spending time with them. Therefore, PersonY feels happy.\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " happy  happy  happy\n",
      "  \n",
      "Based  satisfied  not satisfied  not satisfied\n",
      "</REASONING>\n",
      "PARSED ANSWER:\n",
      " satisfied not satisfied not  satisfied </ANSWER>\n",
      "\n",
      "GROUND TRUTH RATIONALE + ANSWER:\n",
      " PersonX's intent to get PersonY on their way suggests that they are willing to help or want the best for PersonY. Since PersonX is also feeling good, we can infer that PersonY will be happy about this situation and their reaction would be happy.\n",
      "</REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      "<ANSWER> happy </ANSWER>\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "SOURCE: What is the next dialog turn? I would like to go to a 5 star restaurant. Preferably seafood and steak. Okay I have found two options for you. The first is Copland's about 25 miles from you, the other is Silver Slipper Casino, in Gulfport a 30 minuet drive. Which one serves the best seafood? According to their reviews, Silver Slipper Casino has the biggest array, including: Snow crab legs, shrimp, and crayfish. Perfect! Okay I would like to book there. how many reservations do you need, and for what day and time? A table of 20, for let's say, 5pm. Outside as well. We can do a table of 20, but there is no outdoor seating option. How about close to the back of the room, so we can have some privacy? Yes we can arrange that. Also what day is this for? February 3rd at 5pm Okay it seems that on that day for 5pm Silver Slipper Casino is already booked completely. I can get you in either for 4pm or 7pm. I really need it for 5pm otherwise the whole party can't make it. the 6th maybe? Okay, you're in luck! They are open for the 6th.\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "\n",
      "MODEL RAW OUTPUT:\n",
      " ### Prompt: 3\n",
      "### Context: What is the next dialog turn? I would like to go to a 5 star restaurant. Preferably seafood and steak. Okay I have found two options for you. The first is Copland's about 25 miles from you, the other is Silver Slipper Casino, in Gulfport a 30 minuet drive. Which one serves the best seafood? According to their reviews, Silver Slipper Casino has the biggest array, including: Snow crab legs, shrimp, and crayfish. Perfect! Okay I would like to book there. how many reservations do you need, and for what day and time? A table of 20, for let's say, 5pm. Outside as well. We can do a table of 20, but there is no outdoor seating option. How about close to the back of the room, so we can have some privacy? Yes we can arrange that. Also what day is this for? February 3rd at 5pm Okay it seems that on that day for 5pm Silver Slipper Casino is already booked completely. I can get you in either for 4pm or 7pm. I really need it for 5pm otherwise the whole party can't make it. the 6th maybe? Okay, you're in luck! They are open for the 6th.\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      " 6  6  6 n 6\n",
      " 7  7  7 n 7\n",
      " 8  8  8 n 8\n",
      " 9  9  9 n 9\n",
      " 10  10\n",
      "</REASONING>\n",
      "<ANSWER> 10   10 </ANSWER> </ANSWER>\n",
      "\n",
      "PARSED RATIONALE:\n",
      " Based on the reasoning above, the final answer is:\n",
      " 6  6  6 n 6\n",
      " 7  7  7 n 7\n",
      " 8  8  8 n 8\n",
      " 9  9  9 n 9\n",
      " 10  10\n",
      "</REASONING>\n",
      "PARSED ANSWER:\n",
      " 10   10 </ANSWER>\n",
      "\n",
      "GROUND TRUTH RATIONALE + ANSWER:\n",
      " The person is trying to book a table for 20 people at 5pm. The person does not seem satisfied with the room arrangement and is looking for other options. It seems that the only option available for the person's preferred date and time is Silver Slipper Casino, so the answer should be something in line with this fact and should continue from where the conversation left off. In this case, \"Great! Also do they offer alcoholic drinks there?\" fits this criteria perfectly.\"\n",
      "</REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      "<ANSWER> Great! Also do they offer alcoholic drinks there? </ANSWER>\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "SOURCE: Given a premise, an initial context, an original ending, and a new ending, the task is to generate the counterfactual context that is aligned with the new ending. Each instance consists of a five-sentence story. The premise is the first sentence of a story, and the second sentence, which is the initial context, provides more information about the story's context. The original ending is the last three sentences of the story. Also, you are given a new ending that can provide the new story with the same premise. You should write a counterfactual context to explain the small differences between the original and new endings. More specifically, a story context contains the general plot of the story. And a counterfactual context is a slight modification to the initial context. To sum up, you should write the second sentence of a story based on the premise(first sentence) and the new ending(last three sentences) of the story. Premise: Anna was on a ship in the ocean. Initial Context: She was watching the waves eagerly. Original Ending: She hoped to see a mermaid! She tried to scan the entire ocean. But after weeks, she had not seen any mermaids. New ending: Luckily, it was only a dream but she really wanto see a mermaid. She tried to scan the entire ocean. But after weeks, she had not seen any mermaids.\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "\n",
      "MODEL RAW OUTPUT:\n",
      " ### Prompt: none\n",
      "### Context: Given a premise, an initial context, an original ending, and a new ending, the task is to generate the counterfactual context that is aligned with the new ending. Each instance consists of a five-sentence story. The premise is the first sentence of a story, and the second sentence, which is the initial context, provides more information about the story's context. The original ending is the last three sentences of the story. Also, you are given a new ending that can provide the new story with the same premise. You should write a counterfactual context to explain the small differences between the original and new endings. More specifically, a story context contains the general plot of the story. And a counterfactual context is a slight modification to the initial context. To sum up, you should write the second sentence of a story based on the premise(first sentence) and the new ending(last three sentences) of the story. Premise: Anna was on a ship in the ocean. Initial Context: She was watching the waves eagerly. Original Ending: She hoped to see a mermaid! She tried to scan the entire ocean. But after weeks, she had not seen any mermaids. New ending: Luckily, it was only a dream but she really wanto see a mermaid. She tried to scan the entire ocean. But after weeks, she had not seen any mermaids.\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "The new ending is a modification to what was stated in the premise. The new ending provides more details about the background of the original ending and explains why Anna was not able to see mermaid's.\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " new  new  new\n",
      "</REASONING>\n",
      "<ANSWER> new n  new  new </ANSWER> </ANSWER>\n",
      "\n",
      "PARSED RATIONALE:\n",
      " The new ending is a modification to what was stated in the premise. The new ending provides more details about the background of the original ending and explains why Anna was not able to see mermaid's.\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " new  new  new\n",
      "</REASONING>\n",
      "PARSED ANSWER:\n",
      " new n  new  new </ANSWER>\n",
      "\n",
      "GROUND TRUTH RATIONALE + ANSWER:\n",
      " The original and new endings are mostly similar, however, the new one ends with \"It was only a dream\". This implies that some event occurred that caused Anna to fall asleep on the ship. Therefore, we write \"She fell into the water\" as a counterfactual context because it would be likely for Anna to fall asleep after falling into the ocean.\n",
      "</REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      "<ANSWER> She fell into the water </ANSWER>\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "SOURCE: Here is a premise: oh that was one of my favorites Here is a hypothesis: I hate that movie the most. Here are the options: OPTIONS: - yes - it is not possible to tell - no Is it possible to conclude that if the premise is true, then so is the hypothesis?\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "\n",
      "MODEL RAW OUTPUT:\n",
      " ### Prompt: 2\n",
      "### Context: Here is a premise: oh that was one of my favorites Here is a hypothesis: I hate that movie the most. Here are the options: OPTIONS: - yes - it is not possible to tell - no Is it possible to conclude that if the premise is true, then so is the hypothesis?\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "The premise states that the movie \"Oh that was One of My Favorite\" is one of the movies that \"I hate\". The hypothesis states that this is not true, so it cannot be concluded that if both statements are true, they would be true at the same time. So, the answer is \"no\".\n",
      "</REASONING>\n",
      "<ANSWER> no  yes  it is </ANSWER> </ANSWER>\n",
      "\n",
      "PARSED RATIONALE:\n",
      " The premise states that the movie \"Oh that was One of My Favorite\" is one of the movies that \"I hate\". The hypothesis states that this is not true, so it cannot be concluded that if both statements are true, they would be true at the same time. So, the answer is \"no\".\n",
      "</REASONING>\n",
      "PARSED ANSWER:\n",
      " no  yes  it is </ANSWER>\n",
      "\n",
      "GROUND TRUTH RATIONALE + ANSWER:\n",
      " The premise states that the movie is one of her favorites, whereas in the hypothesis she says that it's \"the most\" hated. So even if we assumed that the premise is true (that someone likes a certain move), then how do we conclude whether or not this same person hates this movie? Without an additional context about what makes people hate movies, for example, bringing up other movies to compare with and see why they are more liked than others, there's no way to determine whether the statement holds true.\n",
      "</REASONING>\n",
      "Based on the reasoning above, the final answer is:\n",
      "<ANSWER> no </ANSWER>\n",
      "\n",
      "[Qualitative checklist — mark yes/no]\n",
      " idx coherent_rationale grounded_in_context answer_correct\n",
      "   0                                                      \n",
      "   1                                                      \n",
      "   2                                                      \n",
      "   3                                                      \n",
      "   4                                                      \n",
      "   5                                                      \n",
      "   6                                                      \n",
      "   7                                                      \n",
      "   8                                                      \n",
      "   9                                                      \n",
      "\n",
      "== Quick Answer Metrics on sample ==\n",
      "Exact Match: 0.000 | F1 (token): 0.132\n"
     ]
    }
   ],
   "source": [
    "# ========= 2‑stage generator: first rationale, then answer, with tag EOS =========\n",
    "\n",
    "def _ids_len(x): \n",
    "    return x[\"input_ids\"].shape[-1]\n",
    "\n",
    "def _decode_new(out_ids, in_len):\n",
    "    new_tokens = out_ids[0][in_len:]\n",
    "    return tokenizer.decode(new_tokens, skip_special_tokens=True).strip()\n",
    "\n",
    "# resolve special token ids (fallback if not found)\n",
    "REASON_OPEN = \"<REASONING>\"\n",
    "REASON_CLOSE = \"</REASONING>\"\n",
    "ANS_OPEN    = \"<ANSWER>\"\n",
    "ANS_CLOSE   = \"</ANSWER>\"\n",
    "\n",
    "REASON_CLOSE_ID = tokenizer.convert_tokens_to_ids(REASON_CLOSE)\n",
    "ANS_CLOSE_ID    = tokenizer.convert_tokens_to_ids(ANS_CLOSE)\n",
    "\n",
    "USE_REASON_EOS  = REASON_CLOSE_ID != tokenizer.unk_token_id and REASON_CLOSE_ID != -1\n",
    "USE_ANS_EOS     = ANS_CLOSE_ID    != tokenizer.unk_token_id and ANS_CLOSE_ID    != -1\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_rationale_then_answer(source: str, prompt: str = \"\"):\n",
    "    \"\"\"\n",
    "    Stage 1: generate rationale until </REASONING>\n",
    "    Stage 2: generate answer until </ANSWER>\n",
    "    Returns: rationale_text, answer_text, raw_full_text\n",
    "    \"\"\"\n",
    "    # ---------- Stage 1: RATIONALE ----------\n",
    "    prefix_reason = (\n",
    "        f\"### Prompt: {prompt}\\n\"\n",
    "        f\"### Context: {source}\\n\"\n",
    "        f\"### Chain of Thought:\\n\"\n",
    "        f\"Let's think step by step.\\n\"\n",
    "        f\"{REASON_OPEN}\\n\"\n",
    "    )\n",
    "    inp1 = tokenizer(prefix_reason, return_tensors=\"pt\", truncation=True, max_length=900).to(model.device)\n",
    "    headroom1 = max(32, 1024 - _ids_len(inp1) - 1)\n",
    "\n",
    "    out1 = model.generate(\n",
    "        **inp1,\n",
    "        max_new_tokens=min(256, headroom1),\n",
    "        min_new_tokens=min(64, headroom1),\n",
    "        do_sample=False,\n",
    "        no_repeat_ngram_size=3,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=(REASON_CLOSE_ID if USE_REASON_EOS else tokenizer.eos_token_id),\n",
    "    )\n",
    "    rationale_segment = _decode_new(out1, _ids_len(inp1))\n",
    "    # ensure we end with closing tag text (for cleanliness)\n",
    "    if REASON_CLOSE not in rationale_segment:\n",
    "        rationale_segment = rationale_segment.split(\"###\")[0].strip()\n",
    "        rationale_segment = rationale_segment + f\"\\n{REASON_CLOSE}\"\n",
    "\n",
    "    # ---------- Stage 2: ANSWER ----------\n",
    "    # prefix_answer = prefix_reason + rationale_segment + f\"\\n{ANS_OPEN} \"\n",
    "       # Explicitly tie the answer to the generated reasoning\n",
    "    prefix_answer = (\n",
    "        prefix_reason\n",
    "        + rationale_segment\n",
    "        + \"\\nBased on the reasoning above, the final answer is:\\n\"\n",
    "        + f\"{ANS_OPEN} \"\n",
    "    )\n",
    "    inp2 = tokenizer(prefix_answer, return_tensors=\"pt\", truncation=True, max_length=1000).to(model.device)\n",
    "    headroom2 = max(16, 1024 - _ids_len(inp2) - 1)\n",
    "\n",
    "    out2 = model.generate(\n",
    "        **inp2,\n",
    "        max_new_tokens=min(64, headroom2),\n",
    "        min_new_tokens=min(8, headroom2),\n",
    "        do_sample=False,\n",
    "        no_repeat_ngram_size=3,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=(ANS_CLOSE_ID if USE_ANS_EOS else tokenizer.eos_token_id),\n",
    "    )\n",
    "    answer_segment = _decode_new(out2, _ids_len(inp2))\n",
    "    if ANS_CLOSE not in answer_segment:\n",
    "        # trim at accidental section headers if any\n",
    "        answer_segment = answer_segment.split(\"###\")[0].strip()\n",
    "        answer_segment = answer_segment + f\" {ANS_CLOSE}\"\n",
    "\n",
    "    # ---------- Compose clean strings ----------\n",
    "    # strip tags for display (keeping content)\n",
    "    def between(txt, open_tag, close_tag):\n",
    "        if open_tag in txt and close_tag in txt:\n",
    "            return txt.split(open_tag, 1)[1].split(close_tag, 1)[0].strip()\n",
    "        return txt.strip()\n",
    "\n",
    "    rationale_clean = between(rationale_segment, REASON_OPEN, REASON_CLOSE)\n",
    "    answer_clean    = between(answer_segment, ANS_OPEN, ANS_CLOSE)\n",
    "\n",
    "    full_text = prefix_reason + rationale_segment + \"\\n\" + ANS_OPEN + \" \" + answer_clean + \" \" + ANS_CLOSE\n",
    "    return rationale_clean, answer_clean, full_text\n",
    "\n",
    "# ================= run & display with the new 2‑stage generator =================\n",
    "\n",
    "sampled = safe_sample(eval_ds, k=25, seed=42)\n",
    "print(f\"[info] evaluating on {len(sampled)} examples (eval_ds size = {len(eval_ds)})\")\n",
    "\n",
    "pred_answers, gold_answers = [], []\n",
    "\n",
    "for ex in sampled:\n",
    "    prompt, source = parse_prompt_source(ex[\"text\"])\n",
    "    rationale, answer, raw_full = generate_rationale_then_answer(source, prompt)\n",
    "    gold_ans = ex[\"label\"]\n",
    "    # gold answer text (strip tags if present)\n",
    "    gold_ans_clean = gold_ans\n",
    "    if \"<ANSWER>\" in gold_ans_clean:\n",
    "        gold_ans_clean = gold_ans_clean.split(\"<ANSWER>\", 1)[1].split(\"</ANSWER>\", 1)[0].strip()\n",
    "\n",
    "    pred_answers.append(answer)\n",
    "    gold_answers.append(gold_ans_clean)\n",
    "\n",
    "    print(\"─\" * 80)\n",
    "    print(\"SOURCE:\", source)\n",
    "    print(\"\\nMODEL RAW OUTPUT:\\n\", raw_full)\n",
    "    print(\"\\nPARSED RATIONALE:\\n\", rationale if rationale else \"[none]\")\n",
    "    print(\"PARSED ANSWER:\\n\", answer if answer else \"[none]\")\n",
    "    print(\"\\nGROUND TRUTH RATIONALE + ANSWER:\\n\", ex[\"label\"])\n",
    "\n",
    "# -- Build a small qualitative table for 10–20 samples --\n",
    "import pandas as pd\n",
    "rows = []\n",
    "for i, ex in enumerate(sampled):\n",
    "    # recompute clean gold answer\n",
    "    gold = ex[\"label\"]\n",
    "    if \"<ANSWER>\" in gold:\n",
    "        gold = gold.split(\"<ANSWER>\", 1)[1].split(\"</ANSWER>\", 1)[0].strip()\n",
    "    rows.append({\n",
    "        \"idx\": i,\n",
    "        \"coherent_rationale\": \"\",    # fill manually: yes/no\n",
    "        \"grounded_in_context\": \"\",   # fill manually: yes/no\n",
    "        \"answer_correct\": \"\",        # fill manually: yes/no (compare to gold)\n",
    "    })\n",
    "qual_df = pd.DataFrame(rows)\n",
    "print(\"\\n[Qualitative checklist — mark yes/no]\")\n",
    "print(qual_df.head(10).to_string(index=False))\n",
    "\n",
    "# --- quick metrics (same as before) ---\n",
    "if pred_answers and gold_answers:\n",
    "    em = sum(exact_match(p, g) for p, g in zip(pred_answers, gold_answers)) / len(pred_answers)\n",
    "    f1 = sum(f1_token(p, g)     for p, g in zip(pred_answers, gold_answers)) / len(pred_answers)\n",
    "    print(\"\\n== Quick Answer Metrics on sample ==\")\n",
    "    print(f\"Exact Match: {em:.3f} | F1 (token): {f1:.3f}\")\n",
    "else:\n",
    "    print(\"\\n[warn] No predictions or gold answers to score.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb88d6e4",
   "metadata": {
    "papermill": {
     "duration": 0.026835,
     "end_time": "2025-08-11T09:55:56.159108",
     "exception": false,
     "start_time": "2025-08-11T09:55:56.132273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluation metrics + random/custom testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd7cb118",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T09:55:56.214472Z",
     "iopub.status.busy": "2025-08-11T09:55:56.214157Z",
     "iopub.status.idle": "2025-08-11T09:56:40.655586Z",
     "shell.execute_reply": "2025-08-11T09:56:40.654833Z"
    },
    "papermill": {
     "duration": 44.470783,
     "end_time": "2025-08-11T09:56:40.656918",
     "exception": false,
     "start_time": "2025-08-11T09:55:56.186135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Evaluation on 15 examples]\n",
      " Answer EM:  0.000\n",
      " Answer F1:  0.070\n",
      " Label Accuracy (1 constrained cases): 0.000\n",
      " Rationale ROUGE-L (vs gold): 0.284\n",
      " Rationale Coverage (vs context Jaccard): 0.175\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_snip</th>\n",
       "      <th>pred_answer</th>\n",
       "      <th>gold_answer</th>\n",
       "      <th>EM</th>\n",
       "      <th>F1</th>\n",
       "      <th>ROUGE-L(rationale)</th>\n",
       "      <th>Cov(rationale,context)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Suggest a movie title for the following movie ...</td>\n",
       "      <td>Burke Burke  Harry romani Harry romano Janet S...</td>\n",
       "      <td>Firewall</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In this task you will be given a claim and a p...</td>\n",
       "      <td>undermine n  neutral  neutral &lt;/ANSWER&gt;</td>\n",
       "      <td>undermine</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Question: Tim discovered that his polished flo...</td>\n",
       "      <td>quilted  polished &lt;/ANSWER&gt;</td>\n",
       "      <td>quilt</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In this task you will be given a text passage ...</td>\n",
       "      <td>Ummmaysad   Ummmmaysad n Ummas &lt;/ANSWER&gt;</td>\n",
       "      <td>History</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When enjoying flowers in a recreation area run...</td>\n",
       "      <td>surface \\n  \\n\\nBased &lt;/ANSWER&gt;</td>\n",
       "      <td>state park</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Write the conversation response. DIALOG: Where...</td>\n",
       "      <td>Hayns , Woody , Pearson and Pearson   Pearson ...</td>\n",
       "      <td>What health problems did Gregg Allman have dur...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is the solution? Solve -212514 + 213261 =...</td>\n",
       "      <td>&lt;/ANSWER&gt;</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>You are given a sentence from a conversation b...</td>\n",
       "      <td>Busses  Bus  Ferry  \\n    Ferry\\n Buses is the...</td>\n",
       "      <td>RideSharing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Article: Every family with kids has seen its s...</td>\n",
       "      <td>No n  No No \\n  No Yes &lt;/ANSWER&gt;</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Question: How many doctors saw Frédéric by the...</td>\n",
       "      <td>no n  no The answer is\\n no  yes n no &lt;/ANSWER&gt;</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         source_snip  \\\n",
       "0  Suggest a movie title for the following movie ...   \n",
       "1  In this task you will be given a claim and a p...   \n",
       "2  Question: Tim discovered that his polished flo...   \n",
       "3  In this task you will be given a text passage ...   \n",
       "4  When enjoying flowers in a recreation area run...   \n",
       "5  Write the conversation response. DIALOG: Where...   \n",
       "6  What is the solution? Solve -212514 + 213261 =...   \n",
       "7  You are given a sentence from a conversation b...   \n",
       "8  Article: Every family with kids has seen its s...   \n",
       "9  Question: How many doctors saw Frédéric by the...   \n",
       "\n",
       "                                         pred_answer  \\\n",
       "0  Burke Burke  Harry romani Harry romano Janet S...   \n",
       "1            undermine n  neutral  neutral </ANSWER>   \n",
       "2                        quilted  polished </ANSWER>   \n",
       "3           Ummmaysad   Ummmmaysad n Ummas </ANSWER>   \n",
       "4                    surface \\n  \\n\\nBased </ANSWER>   \n",
       "5  Hayns , Woody , Pearson and Pearson   Pearson ...   \n",
       "6                                          </ANSWER>   \n",
       "7  Busses  Bus  Ferry  \\n    Ferry\\n Buses is the...   \n",
       "8                   No n  No No \\n  No Yes </ANSWER>   \n",
       "9    no n  no The answer is\\n no  yes n no </ANSWER>   \n",
       "\n",
       "                                         gold_answer  EM     F1  \\\n",
       "0                                           Firewall   0  0.000   \n",
       "1                                          undermine   0  0.333   \n",
       "2                                              quilt   0  0.000   \n",
       "3                                            History   0  0.000   \n",
       "4                                         state park   0  0.000   \n",
       "5  What health problems did Gregg Allman have dur...   0  0.039   \n",
       "6                                                 -3   0  0.000   \n",
       "7                                        RideSharing   0  0.000   \n",
       "8                                                 No   0  0.250   \n",
       "9                                                yes   0  0.182   \n",
       "\n",
       "   ROUGE-L(rationale)  Cov(rationale,context)  \n",
       "0               0.171                   0.087  \n",
       "1               0.412                   0.234  \n",
       "2               0.222                   0.222  \n",
       "3               0.451                   0.136  \n",
       "4               0.353                   0.244  \n",
       "5               0.125                   0.209  \n",
       "6               0.354                   0.163  \n",
       "7               0.361                   0.192  \n",
       "8               0.130                   0.026  \n",
       "9               0.311                   0.235  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————————————————————————————————————————————————————————————————————————————————\n",
      "[107] PROMPT: Write a multi-choice question (options given)\n",
      "SOURCE: Write a multi-choice question for the following article, with the given choices and answer: Article: The \"melting pot\" in American cuisine(. ) is a myth, not terribly unlike the idea of a melting pot of American culture, notes chef Dan Barber. \"Most cultures don't think about their cuisine in such monolithic terms,\" he says. \"French, Mexican, Chinese, and Italian cuisines each consist of dozens of distinct regional foods. And I think 'American' cuisine is moving in the same direction, becoming more localized, not globalized. \" American cuisine is shaped by the natural wealth of the country. Having never faced agricultural hardship, Americans don't have to rely on rotating crops, such as the Japanese, whose food culture now showcases buckwheat alongside rice, or the Indians, or the French and Italians, who feature beans alongside wheat. \"That kind of negotiation with the land forced people to incorporate those crops in to the culture,\" says Barber. And so eating soba noodles becomes part of what it means to be Japanese, and eating beans becomes part of what it means to be French. So if what we eat is what we are, what are Americans? Well, meat. \"If Americans have any unifying food identity, I would say we are a mostly white meat culture,\" says Barber. \"The protein-centric dinner plate, whether you're talking about a boneless chicken breast, or a 16-ounce steak, as an everyday expectation is something that America really created, and now exports to the rest of the world.\" Every single culture and religion uses food as part of their celebrations, says Ellen Gustafson, co-founder of the FEED Project and The 30 Project, which aims to deal with both hunger and overweight issues globally. \"The celebratory nature of food is universal. Every season, every harvest, and every holiday has its own food, and this is true in America as well. It helps define us.\" Options: A Relying on rotating crops B The difficulty of planting crops C The US' melting pot culture D The US' agricultural wealth Answer: D The US' agricultural wealth Question:\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "\n",
      "MODEL RATIONALE:\n",
      " The article states that the melting pot is a mythical notion, not very similar to the idea that American cuisine consists of dozens or even hundreds of distinct cuisined foods. The author also says that the US' agriculture wealth is a common theme in American culture and cuisine, which suggests that it is not a myth at all. So the answer is D\n",
      "</REASONING>\n",
      "MODEL ANSWER: D \n",
      " D </ANSWER>\n",
      "\n",
      "GOLD: What has made American cuisine different from other cuisines according to the article?\n",
      "————————————————————————————————————————————————————————————————————————————————\n",
      "[548] PROMPT: pick_the_most_correct_option\n",
      "SOURCE: Pick the most correct option to answer the following question. Which best determines the number of wolves that can live in an area? Options: - A: the amount of snow in the area each year - B: the number of birds that live in the area - C: the number of trees in the area - D: the amount of food available in the area\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "\n",
      "MODEL RATIONALE:\n",
      " The answer is B because the number is determined by the amount and type of snowfall in an individual area.\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " B  C  D  E  F  G  H  I  J  K  L  M  N  O  P  Q  R  S  T  U  V  W  X  Y  Z\n",
      "</REASONING>\n",
      "MODEL ANSWER: D E    F G   H I   J K   L M N O  Q R   S T   U V   W X   Y Y   Z  \n",
      "  D , E , F , G , H , I , J , K , </ANSWER>\n",
      "\n",
      "GOLD: D\n",
      "————————————————————————————————————————————————————————————————————————————————\n",
      "[178] PROMPT: Multiple Choice\n",
      "SOURCE: Answer the following question given this paragraph: The menstrual cycle includes events that take place in the ovary, such as ovulation. It also includes changes in the uterus, including menstruation. Menopause occurs when menstruation stops occurring, usually in middle adulthood. Q: At what time of life does menopause occur? Choices: - old age - young adulthood - adolescence - in middle adulthood A:\n",
      "### Chain of Thought:\n",
      "Let's think step by step.\n",
      "<REASONING>\n",
      "\n",
      "MODEL RATIONALE:\n",
      " The paragraph states that menopausa occurs at middle adulthood, which is when menopulmonary function (the ability to breathe) declines. Therefore, the answer is \"middle adulthood\".\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " middle adulthood  middle adulthood\n",
      "</REASONING>\n",
      "MODEL ANSWER: middle adulthood n middle </ANSWER>\n",
      "\n",
      "GOLD: in middle adulthood\n"
     ]
    }
   ],
   "source": [
    "# ========= Evaluation metrics + random/custom testing =========\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# --- small helpers (reuse-friendly) ---\n",
    "\n",
    "def _norm_text(s: str) -> str:\n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r'\\b(a|an|the)\\b', ' ', s)\n",
    "    s = re.sub(r'[^a-z0-9\\s]', ' ', s)\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    return s\n",
    "\n",
    "def exact_match(pred: str, gold: str) -> int:\n",
    "    return int(_norm_text(pred) == _norm_text(gold))\n",
    "\n",
    "def f1_token(pred: str, gold: str) -> float:\n",
    "    p = _norm_text(pred).split()\n",
    "    g = _norm_text(gold).split()\n",
    "    inter = Counter(p) & Counter(g)\n",
    "    overlap = sum(inter.values())\n",
    "    if not p or not g:\n",
    "        return float(p == g)\n",
    "    prec = overlap / len(p)\n",
    "    rec  = overlap / len(g)\n",
    "    return 0.0 if (prec + rec) == 0 else 2 * prec * rec / (prec + rec)\n",
    "\n",
    "def _lcs(X, Y):\n",
    "    # longest common subsequence length for ROUGE-L\n",
    "    m, n = len(X), len(Y)\n",
    "    dp = [[0]*(n+1) for _ in range(m+1)]\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            if X[i] == Y[j]:\n",
    "                dp[i+1][j+1] = dp[i][j] + 1\n",
    "            else:\n",
    "                dp[i+1][j+1] = max(dp[i][j+1], dp[i+1][j])\n",
    "    return dp[m][n]\n",
    "\n",
    "def rouge_l(pred: str, gold: str) -> float:\n",
    "    # token-level F1 variant of ROUGE-L\n",
    "    P = _norm_text(pred).split()\n",
    "    G = _norm_text(gold).split()\n",
    "    if not P or not G:\n",
    "        return float(P == G)\n",
    "    lcs = _lcs(P, G)\n",
    "    prec = lcs / len(P)\n",
    "    rec  = lcs / len(G)\n",
    "    return 0.0 if (prec + rec) == 0 else 2 * prec * rec / (prec + rec)\n",
    "\n",
    "def jaccard_overlap(a: str, b: str) -> float:\n",
    "    A = set(_norm_text(a).split())\n",
    "    B = set(_norm_text(b).split())\n",
    "    if not A and not B:\n",
    "        return 1.0\n",
    "    if not A or not B:\n",
    "        return 0.0\n",
    "    return len(A & B) / len(A | B)\n",
    "\n",
    "def extract_gold_answer(label_text: str) -> str:\n",
    "    if \"<ANSWER>\" in label_text and \"</ANSWER>\" in label_text:\n",
    "        return label_text.split(\"<ANSWER>\", 1)[1].split(\"</ANSWER>\", 1)[0].strip()\n",
    "    return label_text.strip()\n",
    "\n",
    "def extract_gold_rationale(label_text: str) -> str:\n",
    "    if \"<REASONING>\" in label_text and \"</REASONING>\" in label_text:\n",
    "        return label_text.split(\"<REASONING>\", 1)[1].split(\"</REASONING>\", 1)[0].strip()\n",
    "    return label_text.strip()\n",
    "\n",
    "def constrained_label_accuracy(source_text: str, pred_answer: str, gold_answer: str) -> tuple[bool, str]:\n",
    "    \"\"\"\n",
    "    If the task specifies a closed label set, compute accuracy; else return (None, '').\n",
    "    \"\"\"\n",
    "    s = source_text.lower()\n",
    "    pa = pred_answer.strip().lower()\n",
    "    ga = gold_answer.strip().lower()\n",
    "\n",
    "    # hate / not hate\n",
    "    if \"answer using 'hate' or 'not hate'\" in s:\n",
    "        valid = {\"hate\", \"not hate\"}\n",
    "        return (pa in valid and ga in valid and pa == ga, \"hate/not_hate\")\n",
    "    # yes/no\n",
    "    if re.search(r\"\\boptions:\\s*-\\s*no\\s*-\\s*yes\\b\", s) or \"options: - no - yes\" in s:\n",
    "        valid = {\"yes\", \"no\"}\n",
    "        return (pa in valid and ga in valid and pa == ga, \"yes/no\")\n",
    "    # textual entailment common labels\n",
    "    if re.search(r\"\\b(entails|neutral|contradiction)\\b\", s):\n",
    "        valid = {\"entails\", \"neutral\", \"contradiction\"}\n",
    "        return (pa in valid and ga in valid and pa == ga, \"nli\")\n",
    "    # A-E multiple choice\n",
    "    if re.search(r\"\\boptions?:.*\\b([a-e])\\b\", s, flags=re.IGNORECASE|re.DOTALL):\n",
    "        valid = {\"a\",\"b\",\"c\",\"d\",\"e\"}\n",
    "        pa1 = pa[:1]\n",
    "        ga1 = ga[:1]\n",
    "        return (pa1 in valid and ga1 in valid and pa1 == ga1, \"mcq_A-E\")\n",
    "\n",
    "    return (None, \"\")\n",
    "\n",
    "# --- main evaluation over a subset of eval_ds ---\n",
    "def evaluate_model(eval_dataset, k=100, seed=42):\n",
    "    sampled = eval_dataset.shuffle(seed=seed).select(range(min(k, len(eval_dataset))))\n",
    "    rows = []\n",
    "\n",
    "    ans_em_list, ans_f1_list = [], []\n",
    "    lab_hits, lab_total = 0, 0\n",
    "    rouge_list, cov_list = [], []\n",
    "\n",
    "    for ex in sampled:\n",
    "        prompt, source = parse_prompt_source(ex[\"text\"])\n",
    "        rat, ans, raw = generate_rationale_then_answer(source, prompt)\n",
    "\n",
    "        gold_ans = extract_gold_answer(ex[\"label\"])\n",
    "        gold_rat = extract_gold_rationale(ex[\"label\"])\n",
    "\n",
    "        # answers\n",
    "        ans_em_list.append(exact_match(ans, gold_ans))\n",
    "        ans_f1_list.append(f1_token(ans, gold_ans))\n",
    "\n",
    "        # label accuracy if constrained\n",
    "        hit, mode = constrained_label_accuracy(source, ans, gold_ans)\n",
    "        if hit is not None:\n",
    "            lab_total += 1\n",
    "            lab_hits += int(hit)\n",
    "\n",
    "        # rationales\n",
    "        rouge_list.append(rouge_l(rat, gold_rat))\n",
    "        cov_list.append(jaccard_overlap(rat, source))  # how much rationale shares vocab with context\n",
    "\n",
    "        rows.append({\n",
    "            \"source_snip\": source[:100] + (\"...\" if len(source) > 100 else \"\"),\n",
    "            \"pred_answer\": ans,\n",
    "            \"gold_answer\": gold_ans,\n",
    "            \"EM\": ans_em_list[-1],\n",
    "            \"F1\": round(ans_f1_list[-1], 3),\n",
    "            \"ROUGE-L(rationale)\": round(rouge_list[-1], 3),\n",
    "            \"Cov(rationale,context)\": round(cov_list[-1], 3),\n",
    "        })\n",
    "\n",
    "    # summary\n",
    "    em = np.mean(ans_em_list) if ans_em_list else 0.0\n",
    "    f1 = np.mean(ans_f1_list) if ans_f1_list else 0.0\n",
    "    rouge_mean = np.mean(rouge_list) if rouge_list else 0.0\n",
    "    cov_mean = np.mean(cov_list) if cov_list else 0.0\n",
    "    lab_acc = (lab_hits / lab_total) if lab_total > 0 else None\n",
    "\n",
    "    print(f\"\\n[Evaluation on {len(sampled)} examples]\")\n",
    "    print(f\" Answer EM:  {em:.3f}\")\n",
    "    print(f\" Answer F1:  {f1:.3f}\")\n",
    "    if lab_acc is not None:\n",
    "        print(f\" Label Accuracy ({lab_total} constrained cases): {lab_acc:.3f}\")\n",
    "    print(f\" Rationale ROUGE-L (vs gold): {rouge_mean:.3f}\")\n",
    "    print(f\" Rationale Coverage (vs context Jaccard): {cov_mean:.3f}\")\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    # show a small preview table\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(df.head(10))\n",
    "    except:\n",
    "        print(df.head(10).to_string(index=False))\n",
    "\n",
    "    return {\n",
    "        \"em\": em, \"f1\": f1, \"label_acc\": lab_acc,\n",
    "        \"rougeL\": rouge_mean, \"coverage\": cov_mean,\n",
    "        \"details\": df\n",
    "    }\n",
    "\n",
    "# --- run evaluation (tweak k to 10–20 for the assignment) ---\n",
    "_ = evaluate_model(eval_ds, k=15, seed=42)\n",
    "\n",
    "# --- RANDOM quick check from eval set ---\n",
    "def random_infer(n=3, seed=None):\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    idxs = random.sample(range(len(eval_ds)), k=min(n, len(eval_ds)))\n",
    "    for i in idxs:\n",
    "        ex = eval_ds[i]\n",
    "        prompt, source = parse_prompt_source(ex[\"text\"])\n",
    "        rat, ans, raw = generate_rationale_then_answer(source, prompt)\n",
    "        print(\"—\"*80)\n",
    "        print(f\"[{i}] PROMPT:\", prompt or \"[none]\")\n",
    "        print(\"SOURCE:\", source)\n",
    "        print(\"\\nMODEL RATIONALE:\\n\", rat)\n",
    "        print(\"MODEL ANSWER:\", ans)\n",
    "        print(\"\\nGOLD:\", extract_gold_answer(ex['label']))\n",
    "\n",
    "# try it\n",
    "random_infer(n=3, seed=123)\n",
    "\n",
    "# --- CUSTOM ad‑hoc inference on your own text ---\n",
    "def custom_infer(prompt: str, context: str):\n",
    "    rat, ans, raw = generate_rationale_then_answer(context, prompt)\n",
    "    print(\"PROMPT:\", prompt or \"[none]\")\n",
    "    print(\"CONTEXT:\", context)\n",
    "    print(\"\\nMODEL RATIONALE:\\n\", rat)\n",
    "    print(\"MODEL ANSWER:\", ans)\n",
    "    return rat, ans\n",
    "\n",
    "# example:\n",
    "# custom_infer(\"classification\", \"Given a comment, classify it into a 'hate' or 'not hate': 'I hate you'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47adad69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T09:56:40.714368Z",
     "iopub.status.busy": "2025-08-11T09:56:40.714121Z",
     "iopub.status.idle": "2025-08-11T09:56:44.210152Z",
     "shell.execute_reply": "2025-08-11T09:56:44.209254Z"
    },
    "papermill": {
     "duration": 3.525719,
     "end_time": "2025-08-11T09:56:44.211590",
     "exception": false,
     "start_time": "2025-08-11T09:56:40.685871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT: short_general_knowledge_q\n",
      "CONTEXT: what is 7-9\n",
      "\n",
      "MODEL RATIONALE:\n",
      " The answer is 7.\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " 7  7  7\n",
      " The answer is therefore:\n",
      " 7  7\n",
      " The answer to this question is therefore \"7\".\n",
      " What is the answer to that question?  What is \"What is \" what is the \" answer to \" that question?\"\n",
      "</REASONING>\n",
      "MODEL ANSWER: What's the answer?  \n",
      " What's \" what's the \" what are the answer?\"\n",
      " What's what's what are they answer?\n",
      " The answer here is \"what are they are answer?\" \n",
      " The answer for this question?\n",
      "\n",
      "Based The final answer for the </ANSWER>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('The answer is 7.\\n\\nBased on the reasoning above, the final answer is:\\n 7  7  7\\n The answer is therefore:\\n 7  7\\n The answer to this question is therefore \"7\".\\n What is the answer to that question?  What is \"What is \" what is the \" answer to \" that question?\"\\n</REASONING>',\n",
       " 'What\\'s the answer?  \\n What\\'s \" what\\'s the \" what are the answer?\"\\n What\\'s what\\'s what are they answer?\\n The answer here is \"what are they are answer?\" \\n The answer for this question?\\n\\nBased The final answer for the </ANSWER>')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_infer(\"short_general_knowledge_q\", \"what is 7-9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15e49243",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T09:56:44.269888Z",
     "iopub.status.busy": "2025-08-11T09:56:44.269652Z",
     "iopub.status.idle": "2025-08-11T09:56:46.447694Z",
     "shell.execute_reply": "2025-08-11T09:56:46.446940Z"
    },
    "papermill": {
     "duration": 2.207711,
     "end_time": "2025-08-11T09:56:46.448785",
     "exception": false,
     "start_time": "2025-08-11T09:56:44.241074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT: short_general_knowledge_q\n",
      "CONTEXT: what is 2+4\n",
      "\n",
      "MODEL RATIONALE:\n",
      " The answer is 2 + 4. The question asks what is the answer to this question. The answer is \"2 + 4\" because it is a general knowledge question.\n",
      "\n",
      "Based on the reasoning above, the final answer is:\n",
      " 2 +  2  \n",
      "Based\n",
      "Based upon the reasoning below, the answer is\n",
      " 3  3\n",
      "</REASONING>\n",
      "MODEL ANSWER: n  \n",
      "   3 </ANSWER>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('The answer is 2 + 4. The question asks what is the answer to this question. The answer is \"2 + 4\" because it is a general knowledge question.\\n\\nBased on the reasoning above, the final answer is:\\n 2 +  2  \\nBased\\nBased upon the reasoning below, the answer is\\n 3  3\\n</REASONING>',\n",
       " 'n  \\n   3 </ANSWER>')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_infer(\"short_general_knowledge_q\", \"what is 2+4\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 3423654,
     "sourceId": 5971518,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9049.137131,
   "end_time": "2025-08-11T09:56:50.023500",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-11T07:26:00.886369",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "06bdadaccf2040178eed870f09ec3fee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0a55fcd061644d33bf6bdf9fc5bd5335": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0a7eda59d6e6407283e8a205d99796cc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0b0417e1c5354b7d84501d493796fc01": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0d8cf79826c0449f990f45dff5115a15": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0e4f1c5e099545bdba5977de5e2116e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0ededaa80bde4e8591da61cff30b5da0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "114ea76fb123481c9ff6ec587fb6bff4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "184ae9b204184f98bf8d654371612f35": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1ea6f861eccd45999d253887062575b7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2758f3fa43e647cdaf3b6814e9881099": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2b4ff53e456e432bac59ed9d5ffc3c9b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2e35ad1c5b444bd2b86f794c1a74dbc0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4df7cd36f2844715aafd5498a625670e",
        "IPY_MODEL_dee8f03de1414ceeb790750c4cb976c0",
        "IPY_MODEL_c7e23b500ef14798aae752e5656481fe"
       ],
       "layout": "IPY_MODEL_adc26994de814f6c94f58cdb1e1f7df2",
       "tabbable": null,
       "tooltip": null
      }
     },
     "2f5830101180491fb524bbbde9c128a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9f4ea171a273409ba125d4375d42d818",
       "placeholder": "​",
       "style": "IPY_MODEL_ae4fa28327c945b0ad4811ae16158f54",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     },
     "3024ff1a275e4f06b7538e2b39c46ce6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0b0417e1c5354b7d84501d493796fc01",
       "placeholder": "​",
       "style": "IPY_MODEL_184ae9b204184f98bf8d654371612f35",
       "tabbable": null,
       "tooltip": null,
       "value": " 8000/8000 [00:06&lt;00:00, 1171.83 examples/s]"
      }
     },
     "34055c7a68fa48f0a43cb9b2b70ee007": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "362c3c3812dd468ab7c21c90e7c5c763": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "364cc27cafd04f3eba90f122351e7646": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3c645374e8614791aa874ee5e5ba7b05": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3f85d42e113a45538f3143dcfb18f355": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3fd2a5b920d8459fb1900897deba0550": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "40a406a549304b30b22fc6ee2519d243": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "452f926fe519477c8329d300707e6d91": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "47cc28730e234e0d84925d37abf923dd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "48d9e338f9364827b9f81701b9719605": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_80a1fd5a5af448c69b7c28034939bbb0",
       "placeholder": "​",
       "style": "IPY_MODEL_658ff2696fe64414a59b7ef7700ff8b8",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer.json: 100%"
      }
     },
     "4bfa176eaa3d4d9d866530535e1c846d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4c7de00c15574955814abdebe7270039": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5621a8cfaf2745dbad8561fbc13472aa",
        "IPY_MODEL_905f1b3633204b80a7e5307d9510640c",
        "IPY_MODEL_3024ff1a275e4f06b7538e2b39c46ce6"
       ],
       "layout": "IPY_MODEL_a696d84a59164c1f8ba65994b1310aee",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4df7cd36f2844715aafd5498a625670e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3c645374e8614791aa874ee5e5ba7b05",
       "placeholder": "​",
       "style": "IPY_MODEL_c7ba79f9b5134f7395dc08c6cc2cfade",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "501c5e7557974bcebe6ef600badb18da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5025fab8a0494a36b1fdc2da098d12c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4bfa176eaa3d4d9d866530535e1c846d",
       "placeholder": "​",
       "style": "IPY_MODEL_06bdadaccf2040178eed870f09ec3fee",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "52104c9e1dcd48ba862ad88f6773b917": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "543df1ab97a349978f9e445e043dd62c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5621a8cfaf2745dbad8561fbc13472aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e6dcf1c3887b4899a192b19678d03a58",
       "placeholder": "​",
       "style": "IPY_MODEL_a8e4019fd19b424fa5cbdeb1aee322ed",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     },
     "63cdaf2dfd5442168020ced8728e58b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "645602ae45fa493c95692e756e26414c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "64a9c2f017e64fd29fdf6edea36af03e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "64bfab01372848258256ceb3cb1774f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_47cc28730e234e0d84925d37abf923dd",
       "max": 1355256.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_bebe9b0aa8ba4f8a983ecdc12947191f",
       "tabbable": null,
       "tooltip": null,
       "value": 1355256.0
      }
     },
     "658ff2696fe64414a59b7ef7700ff8b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "65a68b675d304d2ba26c09b69880b883": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0e4f1c5e099545bdba5977de5e2116e9",
       "placeholder": "​",
       "style": "IPY_MODEL_83219c9427e2433e99f431cfc6755812",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "7091838727b345188c3874dd11929df3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a65e2eaaac694f4b9430eea9e1dd1050",
        "IPY_MODEL_a0e79083eecb4193b98c4d44f77c29b0",
        "IPY_MODEL_88feddc71c6d49adb94915f75e1195d7"
       ],
       "layout": "IPY_MODEL_1ea6f861eccd45999d253887062575b7",
       "tabbable": null,
       "tooltip": null
      }
     },
     "70c21fef14e3436091f1507dc3475354": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "725b8b4944294d629952b37adcef3329": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2f5830101180491fb524bbbde9c128a5",
        "IPY_MODEL_a18287471d194c0d93cefcfe92087b90",
        "IPY_MODEL_9d4cd5bcf9ee42799e62905e1b6f9c4c"
       ],
       "layout": "IPY_MODEL_b61808e6e95c4703b0c67ddf99be3d6a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "7dd169df969042ed8eb3ac593c87f554": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7f154271d3cc45829f8e0fcfc3ec0333": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5025fab8a0494a36b1fdc2da098d12c8",
        "IPY_MODEL_e6490ef30e12465e9404addae9331bfb",
        "IPY_MODEL_d2a99d3339b44c359392b45b0226fec2"
       ],
       "layout": "IPY_MODEL_64a9c2f017e64fd29fdf6edea36af03e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "80a1fd5a5af448c69b7c28034939bbb0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "81fc128a757e481fb93349460f491405": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "83219c9427e2433e99f431cfc6755812": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "838e521a0f044fd7b9bd1fd886673869": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "856b35a89e5345b0a5067204516154c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "86b2585072e147dc8e3f56b9ee4e96f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_81fc128a757e481fb93349460f491405",
       "max": 26.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b323d4ca3cee41cdae9dc56b3cbfd439",
       "tabbable": null,
       "tooltip": null,
       "value": 26.0
      }
     },
     "88feddc71c6d49adb94915f75e1195d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2b4ff53e456e432bac59ed9d5ffc3c9b",
       "placeholder": "​",
       "style": "IPY_MODEL_8bda58a4784f459390dcbbb13033d6c6",
       "tabbable": null,
       "tooltip": null,
       "value": " 456k/456k [00:00&lt;00:00, 6.96MB/s]"
      }
     },
     "8bda58a4784f459390dcbbb13033d6c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8cd04ab566b3448fbb7838aec10beafd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_34055c7a68fa48f0a43cb9b2b70ee007",
       "max": 1042301.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_cb8546b5df1a4c019e549885e5806a17",
       "tabbable": null,
       "tooltip": null,
       "value": 1042301.0
      }
     },
     "8d21a109a6514c3c981800d1f398c8fc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8e05afc6af44441c87d56a216b60255a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0d8cf79826c0449f990f45dff5115a15",
       "placeholder": "​",
       "style": "IPY_MODEL_501c5e7557974bcebe6ef600badb18da",
       "tabbable": null,
       "tooltip": null,
       "value": " 124/124 [00:00&lt;00:00, 11.9kB/s]"
      }
     },
     "8feed41c93f4448e8ff88a44642e0221": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_48d9e338f9364827b9f81701b9719605",
        "IPY_MODEL_64bfab01372848258256ceb3cb1774f6",
        "IPY_MODEL_fd0f1aa0b5a34e7b84e736db0b014b5d"
       ],
       "layout": "IPY_MODEL_c82cf6003ece4564a8813c3913e20ea5",
       "tabbable": null,
       "tooltip": null
      }
     },
     "905f1b3633204b80a7e5307d9510640c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3fd2a5b920d8459fb1900897deba0550",
       "max": 8000.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_856b35a89e5345b0a5067204516154c8",
       "tabbable": null,
       "tooltip": null,
       "value": 8000.0
      }
     },
     "954bb20bb4994639849ed07df220d4ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9554571b41fc4ed1bf401ff840b365a9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a848529458ac4c98ad654f890857f9ae",
        "IPY_MODEL_eab832500e164914904d57de3dfc016e",
        "IPY_MODEL_8e05afc6af44441c87d56a216b60255a"
       ],
       "layout": "IPY_MODEL_40a406a549304b30b22fc6ee2519d243",
       "tabbable": null,
       "tooltip": null
      }
     },
     "992ffe523fa74eb5b4934bbb0d2e227d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9d4cd5bcf9ee42799e62905e1b6f9c4c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_452f926fe519477c8329d300707e6d91",
       "placeholder": "​",
       "style": "IPY_MODEL_70c21fef14e3436091f1507dc3475354",
       "tabbable": null,
       "tooltip": null,
       "value": " 2000/2000 [00:01&lt;00:00, 1010.94 examples/s]"
      }
     },
     "9f4ea171a273409ba125d4375d42d818": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9f73ea23f72c4d599bfcb401b59c7374": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a0e79083eecb4193b98c4d44f77c29b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_645602ae45fa493c95692e756e26414c",
       "max": 456318.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7dd169df969042ed8eb3ac593c87f554",
       "tabbable": null,
       "tooltip": null,
       "value": 456318.0
      }
     },
     "a18287471d194c0d93cefcfe92087b90": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e0e9a98a43c242dca6fcf42c8fa64a60",
       "max": 2000.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_63cdaf2dfd5442168020ced8728e58b0",
       "tabbable": null,
       "tooltip": null,
       "value": 2000.0
      }
     },
     "a1a34e76f78d420aad8384d09854f765": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a65e2eaaac694f4b9430eea9e1dd1050": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_838e521a0f044fd7b9bd1fd886673869",
       "placeholder": "​",
       "style": "IPY_MODEL_a1a34e76f78d420aad8384d09854f765",
       "tabbable": null,
       "tooltip": null,
       "value": "merges.txt: 100%"
      }
     },
     "a696d84a59164c1f8ba65994b1310aee": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a848529458ac4c98ad654f890857f9ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_52104c9e1dcd48ba862ad88f6773b917",
       "placeholder": "​",
       "style": "IPY_MODEL_3f85d42e113a45538f3143dcfb18f355",
       "tabbable": null,
       "tooltip": null,
       "value": "generation_config.json: 100%"
      }
     },
     "a8e4019fd19b424fa5cbdeb1aee322ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "adc26994de814f6c94f58cdb1e1f7df2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ae4fa28327c945b0ad4811ae16158f54": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "aec2a080eeeb4d23a6cb2842486eddc4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b323d4ca3cee41cdae9dc56b3cbfd439": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b4ad2229c6ea49f08f442be523ceea16": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b61808e6e95c4703b0c67ddf99be3d6a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b6ffe74607a547c5bbfab4e87b51ee79": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bebe9b0aa8ba4f8a983ecdc12947191f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "bf4ae25851c24c67907ff92e0acc3f1c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c6ffe3c26b1e4980baef05c60d866486": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_65a68b675d304d2ba26c09b69880b883",
        "IPY_MODEL_86b2585072e147dc8e3f56b9ee4e96f9",
        "IPY_MODEL_dd22353f57e2491e97c8b66ebf284b7f"
       ],
       "layout": "IPY_MODEL_cadb4f8abcc242a3ab12e9fae061cde3",
       "tabbable": null,
       "tooltip": null
      }
     },
     "c7ba79f9b5134f7395dc08c6cc2cfade": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c7e23b500ef14798aae752e5656481fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_114ea76fb123481c9ff6ec587fb6bff4",
       "placeholder": "​",
       "style": "IPY_MODEL_f347e25d143e49519852c26fc7d66601",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.52G/1.52G [00:05&lt;00:00, 618MB/s]"
      }
     },
     "c82cf6003ece4564a8813c3913e20ea5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cadb4f8abcc242a3ab12e9fae061cde3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cb8546b5df1a4c019e549885e5806a17": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d2a99d3339b44c359392b45b0226fec2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8d21a109a6514c3c981800d1f398c8fc",
       "placeholder": "​",
       "style": "IPY_MODEL_992ffe523fa74eb5b4934bbb0d2e227d",
       "tabbable": null,
       "tooltip": null,
       "value": " 718/718 [00:00&lt;00:00, 99.0kB/s]"
      }
     },
     "d42dd6d7dc83498bab71d3d22bc7b02d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d7ee7ff77d3c461b9ff2ad10601b55c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d82e0aa1e45946d99063d1bb3ba65603",
        "IPY_MODEL_8cd04ab566b3448fbb7838aec10beafd",
        "IPY_MODEL_e68755d38a9e492fab9c8d4e315dfaac"
       ],
       "layout": "IPY_MODEL_b6ffe74607a547c5bbfab4e87b51ee79",
       "tabbable": null,
       "tooltip": null
      }
     },
     "d82e0aa1e45946d99063d1bb3ba65603": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0a7eda59d6e6407283e8a205d99796cc",
       "placeholder": "​",
       "style": "IPY_MODEL_9f73ea23f72c4d599bfcb401b59c7374",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.json: 100%"
      }
     },
     "dd22353f57e2491e97c8b66ebf284b7f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0ededaa80bde4e8591da61cff30b5da0",
       "placeholder": "​",
       "style": "IPY_MODEL_364cc27cafd04f3eba90f122351e7646",
       "tabbable": null,
       "tooltip": null,
       "value": " 26.0/26.0 [00:00&lt;00:00, 2.87kB/s]"
      }
     },
     "dee8f03de1414ceeb790750c4cb976c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0a55fcd061644d33bf6bdf9fc5bd5335",
       "max": 1519984962.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_954bb20bb4994639849ed07df220d4ef",
       "tabbable": null,
       "tooltip": null,
       "value": 1519984962.0
      }
     },
     "e0e9a98a43c242dca6fcf42c8fa64a60": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e6490ef30e12465e9404addae9331bfb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_543df1ab97a349978f9e445e043dd62c",
       "max": 718.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_362c3c3812dd468ab7c21c90e7c5c763",
       "tabbable": null,
       "tooltip": null,
       "value": 718.0
      }
     },
     "e68755d38a9e492fab9c8d4e315dfaac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d42dd6d7dc83498bab71d3d22bc7b02d",
       "placeholder": "​",
       "style": "IPY_MODEL_aec2a080eeeb4d23a6cb2842486eddc4",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.04M/1.04M [00:00&lt;00:00, 7.91MB/s]"
      }
     },
     "e6dcf1c3887b4899a192b19678d03a58": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eab832500e164914904d57de3dfc016e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bf4ae25851c24c67907ff92e0acc3f1c",
       "max": 124.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2758f3fa43e647cdaf3b6814e9881099",
       "tabbable": null,
       "tooltip": null,
       "value": 124.0
      }
     },
     "f347e25d143e49519852c26fc7d66601": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "faeef750136b427fbba43ab5bc18843b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fd0f1aa0b5a34e7b84e736db0b014b5d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b4ad2229c6ea49f08f442be523ceea16",
       "placeholder": "​",
       "style": "IPY_MODEL_faeef750136b427fbba43ab5bc18843b",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.36M/1.36M [00:00&lt;00:00, 16.8MB/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
